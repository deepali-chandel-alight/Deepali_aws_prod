{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers --index-url=https://artifactory.alight.com/artifactory/api/pypi/python-pypi-remote/simple --trusted-host=artifactory.alight.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install en_core_web_sm-3.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (0,1,2,4,5,9,10,11,12,13,14,15,16,17,18,20,21,23,24,25,26,27,28,29,31,33,39,41,56,57,58,59,63,64,65,67,68,70,71,74,75,77,78,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,106,108,109,110,111,112,113,114,115,116,117,118,119,122,123,124,125,126,127,128,129,130,131,132,134,135,136,137,138,155,156,159,160,161,164,165) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_combined_web_iva_search = pd.read_csv(\"s3://adl-core-sagemaker-studio/external/IVA/combined_new_adult-child_outer_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>search_text</th>\n",
       "      <th>page_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>step child a dependent?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how do i change my dependent daycare deduction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Child last name change</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am trying to add my children as beneficiarie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how much timeoff do i get after the birth of m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input search_text page_name\n",
       "0                            step child a dependent?         NaN       NaN\n",
       "1     how do i change my dependent daycare deduction         NaN       NaN\n",
       "2                             Child last name change         NaN       NaN\n",
       "3  i am trying to add my children as beneficiarie...         NaN       NaN\n",
       "4  how much timeoff do i get after the birth of m...         NaN       NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_web_iva_search[['input','search_text','page_name']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_iva = pd.read_csv(\"s3://adl-core-sagemaker-studio/external/Deepali/IVA_cleaned_labelled(session_id_added).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_iva.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_iva1 = df_iva.drop(['Unnamed: 0','entry_id','client_id','person_internal_id','next_unit_hit',\n",
    "             'previous_unit_hit','response_text','session_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_orig</th>\n",
       "      <th>labels</th>\n",
       "      <th>input_cleaned</th>\n",
       "      <th>input_cleaned_dl</th>\n",
       "      <th>unit_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Open enrollment</td>\n",
       "      <td>Enrollment</td>\n",
       "      <td>open enrol</td>\n",
       "      <td>open enrollment</td>\n",
       "      <td>Annual Enrollment Clarifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enroll in hra</td>\n",
       "      <td>HRA</td>\n",
       "      <td>enrol hra</td>\n",
       "      <td>enroll in hra</td>\n",
       "      <td>Health Reimbursement Account Clarifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIRE DISCOUNT</td>\n",
       "      <td>Discounts Issue</td>\n",
       "      <td>tire discount</td>\n",
       "      <td>tire discount</td>\n",
       "      <td>Discounts Clarifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eligible</td>\n",
       "      <td>HSA related</td>\n",
       "      <td>elig</td>\n",
       "      <td>eligible</td>\n",
       "      <td>Health Savings Account (HSA) Eligible Expenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Need to update my mail address</td>\n",
       "      <td>General Acount issue</td>\n",
       "      <td>need updat mail address</td>\n",
       "      <td>need to update my mail address</td>\n",
       "      <td>Manage Address</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input_orig                labels  \\\n",
       "0                 Open enrollment            Enrollment   \n",
       "1                   enroll in hra                   HRA   \n",
       "2                   TIRE DISCOUNT       Discounts Issue   \n",
       "3                        eligible           HSA related   \n",
       "4  Need to update my mail address  General Acount issue   \n",
       "\n",
       "             input_cleaned                input_cleaned_dl  \\\n",
       "0               open enrol                 open enrollment   \n",
       "1                enrol hra                   enroll in hra   \n",
       "2            tire discount                   tire discount   \n",
       "3                     elig                        eligible   \n",
       "4  need updat mail address  need to update my mail address   \n",
       "\n",
       "                                        unit_name  \n",
       "0                     Annual Enrollment Clarifier  \n",
       "1          Health Reimbursement Account Clarifier  \n",
       "2                             Discounts Clarifier  \n",
       "3  Health Savings Account (HSA) Eligible Expenses  \n",
       "4                                  Manage Address  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iva1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_iva2 = df_iva1.drop(['input_cleaned','input_cleaned_dl'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_orig</th>\n",
       "      <th>labels</th>\n",
       "      <th>unit_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Open enrollment</td>\n",
       "      <td>Enrollment</td>\n",
       "      <td>Annual Enrollment Clarifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enroll in hra</td>\n",
       "      <td>HRA</td>\n",
       "      <td>Health Reimbursement Account Clarifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIRE DISCOUNT</td>\n",
       "      <td>Discounts Issue</td>\n",
       "      <td>Discounts Clarifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eligible</td>\n",
       "      <td>HSA related</td>\n",
       "      <td>Health Savings Account (HSA) Eligible Expenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Need to update my mail address</td>\n",
       "      <td>General Acount issue</td>\n",
       "      <td>Manage Address</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input_orig                labels  \\\n",
       "0                 Open enrollment            Enrollment   \n",
       "1                   enroll in hra                   HRA   \n",
       "2                   TIRE DISCOUNT       Discounts Issue   \n",
       "3                        eligible           HSA related   \n",
       "4  Need to update my mail address  General Acount issue   \n",
       "\n",
       "                                        unit_name  \n",
       "0                     Annual Enrollment Clarifier  \n",
       "1          Health Reimbursement Account Clarifier  \n",
       "2                             Discounts Clarifier  \n",
       "3  Health Savings Account (HSA) Eligible Expenses  \n",
       "4                                  Manage Address  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iva2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_iva3 = pd.read_csv(\"s3://adl-core-sagemaker-studio/external/Deepali/IVA_cleaned_labelled_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>person_internal_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>input_orig</th>\n",
       "      <th>response_text</th>\n",
       "      <th>unit_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>342020022</td>\n",
       "      <td>13134207</td>\n",
       "      <td>does my fsa carry over</td>\n",
       "      <td>This information isn't available yet.</td>\n",
       "      <td>Flexible Spending Account (FSA) Rollover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>936</td>\n",
       "      <td>12351089</td>\n",
       "      <td>13134208</td>\n",
       "      <td>hi | leave/time off</td>\n",
       "      <td>Hi there. What would you like help with today?...</td>\n",
       "      <td>Hello | Paid Time Off Clarifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>936</td>\n",
       "      <td>32861032</td>\n",
       "      <td>13134215</td>\n",
       "      <td>How much does covid pay cover</td>\n",
       "      <td>For possible impacts to your benefits related ...</td>\n",
       "      <td>Natural Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5888</td>\n",
       "      <td>379001056</td>\n",
       "      <td>13134216</td>\n",
       "      <td>I want to roll my future builder into an ira |...</td>\n",
       "      <td>It looks like you're asking about your FutureB...</td>\n",
       "      <td>401k/403b/457 Clarifier | I Don't Know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1040</td>\n",
       "      <td>147720041</td>\n",
       "      <td>13134224</td>\n",
       "      <td>cancel dental</td>\n",
       "      <td>There are 2 ways to cancel your benefits cover...</td>\n",
       "      <td>Cancel Coverage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  person_internal_id  session_id  \\\n",
       "0        245           342020022    13134207   \n",
       "1        936            12351089    13134208   \n",
       "2        936            32861032    13134215   \n",
       "3       5888           379001056    13134216   \n",
       "4       1040           147720041    13134224   \n",
       "\n",
       "                                          input_orig  \\\n",
       "0                             does my fsa carry over   \n",
       "1                                hi | leave/time off   \n",
       "2                      How much does covid pay cover   \n",
       "3  I want to roll my future builder into an ira |...   \n",
       "4                                      cancel dental   \n",
       "\n",
       "                                       response_text  \\\n",
       "0              This information isn't available yet.   \n",
       "1  Hi there. What would you like help with today?...   \n",
       "2  For possible impacts to your benefits related ...   \n",
       "3  It looks like you're asking about your FutureB...   \n",
       "4  There are 2 ways to cancel your benefits cover...   \n",
       "\n",
       "                                  unit_name  \n",
       "0  Flexible Spending Account (FSA) Rollover  \n",
       "1           Hello | Paid Time Off Clarifier  \n",
       "2                          Natural Disaster  \n",
       "3    401k/403b/457 Clarifier | I Don't Know  \n",
       "4                           Cancel Coverage  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iva3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_iva3 = df_iva3.rename(columns={'input_orig':'input_orig_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_iva3 = df_iva3.drop(['client_id','person_internal_id','session_id','response_text','unit_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_iva3['input_orig_1'].head(10).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the 'col' column using '|' delimiter\n",
    "df_iva3['input_orig_1'] = df_iva3['input_orig_1'].str.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "df_iva3 = df_iva3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_combined_web_iva_search, df_iva2, df_iva3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concat2 = df_concat[['input','input_orig_1','input_orig','search_text','page_name','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select the columns to stack\n",
    "cols_to_stack = ['input', 'input_orig_1', 'input_orig']\n",
    "\n",
    "# stack the columns using melt\n",
    "stacked = pd.melt(df_concat2, id_vars=['search_text', 'page_name', 'labels'], \n",
    "                  value_vars=cols_to_stack, var_name='stacked_cols', value_name='stacked_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_text</th>\n",
       "      <th>page_name</th>\n",
       "      <th>labels</th>\n",
       "      <th>stacked_cols</th>\n",
       "      <th>stacked_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enrollment</td>\n",
       "      <td>input</td>\n",
       "      <td>step child a dependent?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HRA</td>\n",
       "      <td>input</td>\n",
       "      <td>how do i change my dependent daycare deduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discounts Issue</td>\n",
       "      <td>input</td>\n",
       "      <td>Child last name change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HSA related</td>\n",
       "      <td>input</td>\n",
       "      <td>i am trying to add my children as beneficiarie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General Acount issue</td>\n",
       "      <td>input</td>\n",
       "      <td>how much timeoff do i get after the birth of m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  search_text page_name                labels stacked_cols  \\\n",
       "0         NaN       NaN            Enrollment        input   \n",
       "1         NaN       NaN                   HRA        input   \n",
       "2         NaN       NaN       Discounts Issue        input   \n",
       "3         NaN       NaN           HSA related        input   \n",
       "4         NaN       NaN  General Acount issue        input   \n",
       "\n",
       "                                       stacked_input  \n",
       "0                            step child a dependent?  \n",
       "1     how do i change my dependent daycare deduction  \n",
       "2                             Child last name change  \n",
       "3  i am trying to add my children as beneficiarie...  \n",
       "4  how much timeoff do i get after the birth of m...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacked_input    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# use applymap to check the type of each element in the DataFrame\n",
    "list_cols = stacked.applymap(lambda x: isinstance(x, list)).any()\n",
    "\n",
    "# print the list columns\n",
    "print(list_cols[list_cols == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'benefits for eligibility for children'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked['stacked_input'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6990198, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked.dropna(subset=['search_text','page_name','stacked_input'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked['stacked_input'] = stacked['stacked_input'].apply(str)\n",
    "stacked.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_text</th>\n",
       "      <th>page_name</th>\n",
       "      <th>labels</th>\n",
       "      <th>stacked_cols</th>\n",
       "      <th>stacked_input</th>\n",
       "      <th>stacked_input1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enrollment</td>\n",
       "      <td>input</td>\n",
       "      <td>step child a dependent?</td>\n",
       "      <td>step child a dependent?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HRA</td>\n",
       "      <td>input</td>\n",
       "      <td>how do i change my dependent daycare deduction</td>\n",
       "      <td>how do i change my dependent daycare deduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discounts Issue</td>\n",
       "      <td>input</td>\n",
       "      <td>Child last name change</td>\n",
       "      <td>Child last name change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HSA related</td>\n",
       "      <td>input</td>\n",
       "      <td>i am trying to add my children as beneficiarie...</td>\n",
       "      <td>i am trying to add my children as beneficiarie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General Acount issue</td>\n",
       "      <td>input</td>\n",
       "      <td>how much timeoff do i get after the birth of m...</td>\n",
       "      <td>how much timeoff do i get after the birth of m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  search_text page_name                labels stacked_cols  \\\n",
       "0         NaN       NaN            Enrollment        input   \n",
       "1         NaN       NaN                   HRA        input   \n",
       "2         NaN       NaN       Discounts Issue        input   \n",
       "3         NaN       NaN           HSA related        input   \n",
       "4         NaN       NaN  General Acount issue        input   \n",
       "\n",
       "                                       stacked_input  \\\n",
       "0                            step child a dependent?   \n",
       "1     how do i change my dependent daycare deduction   \n",
       "2                             Child last name change   \n",
       "3  i am trying to add my children as beneficiarie...   \n",
       "4  how much timeoff do i get after the birth of m...   \n",
       "\n",
       "                                      stacked_input1  \n",
       "0                            step child a dependent?  \n",
       "1     how do i change my dependent daycare deduction  \n",
       "2                             Child last name change  \n",
       "3  i am trying to add my children as beneficiarie...  \n",
       "4  how much timeoff do i get after the birth of m...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked = stacked.drop(['stacked_cols','stacked_input1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3544788, 4)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.data.path.append('../../nltk_data')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(df, text_cols):\n",
    "    # Create a new dataframe to hold the cleaned text columns\n",
    "    cleaned_df = pd.DataFrame()\n",
    "    \n",
    "    # Define the list of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Clean each text column and add it to the cleaned dataframe\n",
    "    for text_col in text_cols:\n",
    "        text_list = df[text_col].tolist()\n",
    "        text_list = [str(text) for text in text_list]\n",
    "        text_list = [text if text.strip() and not\n",
    "                     set(text).issubset(set(string.punctuation + string.whitespace)) else '' \n",
    "                     for text in text_list]\n",
    "        text_list = [x.lower() for x in text_list]\n",
    "        translator = str.maketrans(string.punctuation + string.digits + \"_\", \" \" * len(\n",
    "            string.punctuation + string.digits + \"_\"))\n",
    "        cleaned_list = []\n",
    "        for text in text_list:\n",
    "            cleaned_text = text.translate(translator)\n",
    "            cleaned_text = ' '.join(cleaned_text.split())\n",
    "            cleaned_text = ' '.join([word for word in cleaned_text.split() if word not in stop_words])\n",
    "            cleaned_list.append(cleaned_text)\n",
    "        cleaned_df[text_col] = cleaned_list\n",
    "    \n",
    "    # Add the non-text columns to the cleaned dataframe\n",
    "    for col in df.columns:\n",
    "        if col not in text_cols:\n",
    "            cleaned_df[col] = df[col]\n",
    "    \n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat3 = clean_text(stacked, text_cols=['stacked_input','search_text','page_name'])\n",
    "# cleaned_stacked, removed_rows = clean_text(stacked, text_cols=['stacked_input','search_text','page_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stacked_input</th>\n",
       "      <th>search_text</th>\n",
       "      <th>page_name</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>step child dependent</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Enrollment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>change dependent daycare deduction</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>HRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>child last name change</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Discounts Issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trying add children beneficiaries life ins</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>HSA related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>much timeoff get birth child</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>General Acount issue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                stacked_input search_text page_name  \\\n",
       "0                        step child dependent         nan       nan   \n",
       "1          change dependent daycare deduction         nan       nan   \n",
       "2                      child last name change         nan       nan   \n",
       "3  trying add children beneficiaries life ins         nan       nan   \n",
       "4                much timeoff get birth child         nan       nan   \n",
       "\n",
       "                 labels  \n",
       "0            Enrollment  \n",
       "1                   HRA  \n",
       "2       Discounts Issue  \n",
       "3           HSA related  \n",
       "4  General Acount issue  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stacked_input</th>\n",
       "      <th>search_text</th>\n",
       "      <th>page_name</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>step child dependent</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Enrollment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>change dependent daycare deduction</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>child last name change</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Discounts Issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trying add children beneficiaries life ins</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HSA related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>much timeoff get birth child</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>General Acount issue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                stacked_input search_text page_name  \\\n",
       "0                        step child dependent                         \n",
       "1          change dependent daycare deduction                         \n",
       "2                      child last name change                         \n",
       "3  trying add children beneficiaries life ins                         \n",
       "4                much timeoff get birth child                         \n",
       "\n",
       "                 labels  \n",
       "0            Enrollment  \n",
       "1                   HRA  \n",
       "2       Discounts Issue  \n",
       "3           HSA related  \n",
       "4  General Acount issue  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat4 = df_concat3.replace('nan', '')\n",
    "df_concat4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concat4['text'] = df_concat4[['stacked_input', 'search_text', 'page_name']].apply(lambda x: ' '.join([str(i) for i in x if not pd.isna(i)]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concat4.drop(['stacked_input','search_text','page_name'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enrollment</td>\n",
       "      <td>step child dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HRA</td>\n",
       "      <td>change dependent daycare deduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discounts Issue</td>\n",
       "      <td>child last name change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HSA related</td>\n",
       "      <td>trying add children beneficiaries life ins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Acount issue</td>\n",
       "      <td>much timeoff get birth child</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 labels                                          text\n",
       "0            Enrollment                        step child dependent  \n",
       "1                   HRA          change dependent daycare deduction  \n",
       "2       Discounts Issue                      child last name change  \n",
       "3           HSA related  trying add children beneficiaries life ins  \n",
       "4  General Acount issue                much timeoff get birth child  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concat4.drop_duplicates(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2723446, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# Get the value counts of the 'labels' column\n",
    "label_counts = df_concat4['labels'].value_counts()\n",
    "print(sum(label_counts>500))\n",
    "# Filter the dataframe to only include rows where the label count is greater than 10000\n",
    "df_concat5 = df_concat4[df_concat4['labels'].isin(label_counts[label_counts > 10000].index)]\n",
    "\n",
    "# Get the shape of the resulting filtered dataframe\n",
    "df_concat5_shape = df_concat5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(844284, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat5_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                    233157\n",
       "Health Benefits          107610\n",
       "Savings Plan              51320\n",
       "Login Issue               44497\n",
       "Dependent issue           40079\n",
       "Clarifier Issue           39129\n",
       "General Account issue     35468\n",
       "Insurance Card            32086\n",
       "Enrollment                29221\n",
       "Loan related              23082\n",
       "HSA related               23059\n",
       "Pension Issue             22212\n",
       "Payment Issue             16794\n",
       "Holiday/Leave Issue       16012\n",
       "Benefciary Issue          13953\n",
       "Dental Plan               13088\n",
       "Coverage Issue            12940\n",
       "Tax related               12334\n",
       "IVA help                  12187\n",
       "Retirement                12042\n",
       "W-2 Form                  11705\n",
       "General Acount issue      11335\n",
       "Claims                    10527\n",
       "Life Insurance            10415\n",
       "Direct Deposit            10032\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat5['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat4[df_concat4['text']=='nan '].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding the texts which contain exact phrases from synonyms list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_3 = ['grand parents','elder','elder women',\n",
    " 'silver generation','elder',\n",
    " 'retiree','Pensioner','Mature adults','Octogenarians','Nonagenarians','Centenarians',\n",
    "'elderly people',\n",
    " 'senior assistance',\n",
    " 'grey generation',\n",
    " 'silver generation',\n",
    " 'senior health',\n",
    " 'elderly companion',\n",
    " 'senior citizen',\n",
    " 'elder support',\n",
    " 'elderly',\n",
    " 'senior members',\n",
    " 'elder population',\n",
    " 'elderly residents',\n",
    " 'senior assistance',\n",
    " 'grey generation',\n",
    " 'elder statesmen',\n",
    " 'elderly',\n",
    " 'elderly people',\n",
    " 'elderly residents',\n",
    " 'elder',\n",
    " 'elder women',\n",
    " 'senior','senior citizen',\n",
    " 'elder generation',\n",
    " 'gerontology',\n",
    " 'elderly population',\n",
    " 'senior members',\n",
    " 'retirees',\n",
    " 'elderly population',\n",
    " 'eldercare',\n",
    " 'geriatric',\n",
    " 'elder statesmen',\n",
    " 'retirees',\n",
    " 'elder population',\n",
    "'eldercae', 'eldercarr', 'eldermann',\n",
    "'eldercre','eldery','elderman','elders','eldercrae']\n",
    "words_4 = list(set([word.lower() for word in words_3]))\n",
    "len(words_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enrollment</td>\n",
       "      <td>step child dependent</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HRA</td>\n",
       "      <td>change dependent daycare deduction</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discounts Issue</td>\n",
       "      <td>child last name change</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HSA related</td>\n",
       "      <td>trying add children beneficiaries life ins</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Acount issue</td>\n",
       "      <td>much timeoff get birth child</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 labels                                          text category\n",
       "0            Enrollment                        step child dependent           \n",
       "1                   HRA          change dependent daycare deduction           \n",
       "2       Discounts Issue                      child last name change           \n",
       "3           HSA related  trying add children beneficiaries life ins           \n",
       "4  General Acount issue                much timeoff get birth child           "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_concat4['text'].str.contains(r'\\b(' + '|'.join(words_4) + r')\\b', case=False, na=False))\n",
    "\n",
    "df_concat4['category'] = ''\n",
    "df_concat4.loc[mask, 'category'] = 'Elder care'\n",
    "# df_combined_web_iva_search.loc[df_combined_web_iva_search['category'] == '', 'category'] = 'Other'\n",
    "\n",
    "df_concat4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_concat4[df_concat4['category']=='Elder care'].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45791, 3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat4[df_concat4['category']=='Elder care'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_concat4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-51ba25ba2911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_concat4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ec_df_concat4.pqt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_concat4' is not defined"
     ]
    }
   ],
   "source": [
    "df_concat4.to_parquet('ec_df_concat4.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concat4 = pd.read_parquet('ec_df_concat4.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              2677655\n",
       "Elder care      45791\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat4['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get text which are similar to phrases in synonnyms list for texts other than which are filtered above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_similar_sentences(df, sentences, phrases, threshold=0.90, category_name = 'Elder care'):\n",
    "    # encode the phrases using the model\n",
    "    phrase_embeddings = model.encode(phrases, convert_to_tensor=True)\n",
    "    \n",
    "    # initialize an empty list to store the similar sentences\n",
    "    similar_sentences = []\n",
    "    similar_phrases = []\n",
    "    \n",
    "    # iterate over the sentences\n",
    "    for sentence in sentences:\n",
    "        # encode the sentence using the model\n",
    "        sentence_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "        # reshape the sentence embedding to a 2D array\n",
    "        sentence_embedding = sentence_embedding.reshape(1, -1)\n",
    "        \n",
    "        # calculate the cosine similarity between the sentence embedding and each phrase embedding\n",
    "        cosine_scores = 1 - cosine_distances(sentence_embedding, phrase_embeddings)\n",
    "        \n",
    "        # convert the cosine similarity scores to a list\n",
    "        scores_list = cosine_scores.tolist()[0]\n",
    "        \n",
    "        # iterate over the phrases and similarity scores and append the sentence to the list if it meets the threshold for at least one phrase\n",
    "        for phrase, score in zip(phrases, scores_list):\n",
    "            if score >= threshold:\n",
    "                similar_sentences.append(sentence)\n",
    "                similar_phrases.append(phrase)\n",
    "                break\n",
    "    \n",
    "    # convert the list of similar sentences to a set to remove duplicates\n",
    "    similar_sentences = set(similar_sentences)\n",
    "    \n",
    "    # create a new dataframe containing only the rows with text that is in the set of similar sentences\n",
    "    similar_df = df[df['text'].isin(similar_sentences)]\n",
    "    similar_df['synonym_phrase'] = similar_phrases\n",
    "    similar_df['category']=category_name\n",
    "    return similar_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def find_similar_sentences(df, sentences, phrases, threshold=0.90, category_name = 'Elder care'):\n",
    "#     # encode the phrases using the model\n",
    "#     phrase_embeddings = model.encode(phrases, convert_to_tensor=True)\n",
    "    \n",
    "#     # initialize an empty list to store the similar sentences\n",
    "#     similar_sentences = []\n",
    "    \n",
    "#     # iterate over the sentences\n",
    "#     for sentence in sentences:\n",
    "#         # encode the sentence using the model\n",
    "#         sentence_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "#         # reshape the sentence embedding to a 2D array\n",
    "#         sentence_embedding = sentence_embedding.reshape(1, -1)\n",
    "        \n",
    "#         # calculate the cosine similarity between the sentence embedding and each phrase embedding\n",
    "#         cosine_scores = 1 - cosine_distances(sentence_embedding, phrase_embeddings)\n",
    "        \n",
    "#         # convert the cosine similarity scores to a list\n",
    "#         scores_list = cosine_scores.tolist()[0]\n",
    "        \n",
    "#         # iterate over the phrases and similarity scores and append the sentence to the list if it meets the threshold for at least one phrase\n",
    "#         for phrase, score in zip(phrases, scores_list):\n",
    "#             if score >= threshold:\n",
    "#                 similar_sentences.append(sentence)\n",
    "#                 break\n",
    "    \n",
    "#     # convert the list of similar sentences to a set to remove duplicates\n",
    "#     similar_sentences = set(similar_sentences)\n",
    "    \n",
    "#     # create a new dataframe containing only the rows with text that is in the set of similar sentences\n",
    "#     similar_df = df[df['text'].isin(similar_sentences)]\n",
    "#     similar_df['category']=category_name\n",
    "#     return similar_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat4 = df_concat4.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "similar_df = find_similar_sentences(\n",
    "    df_concat4,\n",
    "    df_concat4[df_concat4['category']==''].sample(500000, random_state=123)['text'].to_list(),\n",
    "    words_4,\n",
    "    threshold=0.90,\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "similar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_df.to_csv('ec_similar_df_90%_outof_500000_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_EC_df = pd.concat([df_concat4[df_concat4['category']=='Elder care'], \n",
    "                       similar_df]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662, 4)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_EC_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_EC_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_EC_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_similar_df = df_concat4[~df_concat4['text'].isin(only_EC_df['text'])]\n",
    "\n",
    "non_similar_df['category'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat([only_EC_df, non_similar_df]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concatenated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated[(df_concatenated.text.str.contains('elder')) & (df_concatenated.category=='Other')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concatenated[df_concatenated.category=='Elder care'].to_excel('fasttext_only_elder_care_training_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## number og labels in label col where value of category col is Other\n",
    "df_concatenated[df_concatenated['category'] == 'Other']['labels'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concatenated2 = df_concatenated.drop('session_start_cst', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concatenated2['labels'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concatenated2['category'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_concatenated2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_concatenated2\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_concatenated2' is not defined"
     ]
    }
   ],
   "source": [
    "df_concatenated2['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_concatenated2['labels'] = df_concatenated2['labels'].fillna('empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "Other                 0.227158\n",
      "Health Benefits       0.101629\n",
      "Savings Plan          0.042729\n",
      "Clarifier Issue       0.036718\n",
      "Dependent issue       0.036023\n",
      "                        ...   \n",
      "RMSA                  0.000009\n",
      "Rebalancing Issue     0.000009\n",
      "Financial Advisors    0.000009\n",
      "Facilities Issue      0.000009\n",
      "Hysterectomy          0.000009\n",
      "Name: labels, Length: 166, dtype: float64\n",
      "\n",
      "Sampled dataset:\n",
      "Other              0.2336\n",
      "Health Benefits    0.1056\n",
      "Savings Plan       0.0374\n",
      "Dependent issue    0.0366\n",
      "Clarifier Issue    0.0354\n",
      "                    ...  \n",
      "Care Issue         0.0002\n",
      "Plan               0.0002\n",
      "Brokerage          0.0002\n",
      "HR related         0.0002\n",
      "Deferrals          0.0002\n",
      "Name: labels, Length: 130, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## get 5000 rows including all labels where category is Other in same proportion as original \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define the number of folds to use for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create a StratifiedKFold object to generate the cross-validation folds\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Define an empty DataFrame to store the sampled data\n",
    "Other_sample_df = pd.DataFrame()\n",
    "\n",
    "# Split the DataFrame into training and testing sets using cross-validation\n",
    "for train_index, test_index in skf.split(df_concatenated2[df_concatenated2['category'] == 'Other'], \n",
    "                                         df_concatenated2[df_concatenated2['category'] == 'Other']['labels']):\n",
    "    # Obtain a random sample of 5000 rows from the training set\n",
    "    train_df = df_concatenated2.iloc[train_index]\n",
    "    train_df_other = train_df[train_df['category'] == 'Other']\n",
    "    train_df_other_sample = train_df_other.sample(n=5000//n_splits, random_state=42)\n",
    "    Other_sample_df = pd.concat([Other_sample_df, train_df_other_sample])\n",
    "    \n",
    "# Print the value counts of the label column in the original DataFrame and the sample\n",
    "print('Original dataset:')\n",
    "print(df_concatenated2[df_concatenated2['category'] == 'Other']['labels'].value_counts(normalize=True))\n",
    "print('\\nSampled dataset:')\n",
    "print(Other_sample_df['labels'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73147</th>\n",
       "      <td>Health Benefits</td>\n",
       "      <td>need find child care resources birth child</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92005</th>\n",
       "      <td>Loan related</td>\n",
       "      <td>coverage ending child</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93949</th>\n",
       "      <td>Other</td>\n",
       "      <td>checking child care plus wondering reason denied  hmcstmchildcarepluslandingpageopen</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18560</th>\n",
       "      <td>Form 1095 Issue</td>\n",
       "      <td>child colleague scholarship</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51422</th>\n",
       "      <td>Rollovers Clarifier</td>\n",
       "      <td>child goes state college covered insurance</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    labels  \\\n",
       "73147      Health Benefits   \n",
       "92005         Loan related   \n",
       "93949                Other   \n",
       "18560      Form 1095 Issue   \n",
       "51422  Rollovers Clarifier   \n",
       "\n",
       "                                                                                       text  \\\n",
       "73147                                           need find child care resources birth child    \n",
       "92005                                                               coverage ending child     \n",
       "93949  checking child care plus wondering reason denied  hmcstmchildcarepluslandingpageopen   \n",
       "18560                                                         child colleague scholarship     \n",
       "51422                                          child goes state college covered insurance     \n",
       "\n",
       "      category  \n",
       "73147    Other  \n",
       "92005    Other  \n",
       "93949    Other  \n",
       "18560    Other  \n",
       "51422    Other  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Other_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EC_model_train_df = pd.concat([df_concatenated2[df_concatenated2.category=='Elder care'], \n",
    "                              Other_sample_df]).sample(frac=1).reset_index(drop=True)#.to_excel('fasttext_EC_model_training_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>hi life event need add children insurance</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td>elder care elderly care contentpage health care fsa day care dcap page</td>\n",
       "      <td>Elder care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Savings Plan</td>\n",
       "      <td>hi lisa accidently added two sons dependent children removed redo add fix proceed</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Loan related</td>\n",
       "      <td>service offered hearst help elderly family number</td>\n",
       "      <td>Elder care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other</td>\n",
       "      <td>much plan cost employee children plan</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         labels  \\\n",
       "0         Other   \n",
       "1         Other   \n",
       "2  Savings Plan   \n",
       "3  Loan related   \n",
       "4         Other   \n",
       "\n",
       "                                                                                  text  \\\n",
       "0                                          hi life event need add children insurance     \n",
       "1               elder care elderly care contentpage health care fsa day care dcap page   \n",
       "2  hi lisa accidently added two sons dependent children removed redo add fix proceed     \n",
       "3                                  service offered hearst help elderly family number     \n",
       "4                                              much plan cost employee children plan     \n",
       "\n",
       "     category  \n",
       "0       Other  \n",
       "1  Elder care  \n",
       "2       Other  \n",
       "3  Elder care  \n",
       "4       Other  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EC_model_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other         0.752899\n",
       "Elder care    0.247101\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EC_model_train_df.category.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6641, 3)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EC_model_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def count_intnt_entits(text):\n",
    "    doc = nlp(text)\n",
    "    intents = [token.text for token in doc if token.pos_ == 'VERB']\n",
    "    entities = [token.text for token in doc if token.pos_ in {'NOUN', 'PROPN', 'ADJ', 'NUM', 'ADV'}]\n",
    "    return len(intents), len(entities)\n",
    "\n",
    "def extract_ner_entities(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "    return entities\n",
    "\n",
    "def length_entities(list_entities):\n",
    "    if (list_entities==np.nan or list_entities==None or list_entities==''):\n",
    "        return 0\n",
    "    else:\n",
    "        return len(list_entities)\n",
    "    \n",
    "def filter_named_entities(text):\n",
    "    # Process the text using Spacy\n",
    "    doc = nlp(text)\n",
    "    # Filter out named entities (ORG, PERSON, and GPE tags)\n",
    "    filtered_words = [token.text for token in doc if token.ent_type_ not in ['ORG', 'PERSON', 'GPE', \"LOC\", \"FAC\"]]\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "    \n",
    "# list_1 = ['ira','RMD','HRdirect','livechat','what is my hsa','P45','Payslip?',\n",
    "#     'sps','F80.2','ub','What is YSA','Paystub please','Sh','mfv','C-128','ax','no is hsa','FormL564','HIS','cif','GreT','YSACard',\n",
    "#     'Heli','RxPCN','403(b)','Hsa yes or no','ypr','Gv','ONA?','What is UHC?','HC-2','uo','what is 4DX?','osh','what is my hsa?',\n",
    "#     'sPRAVATO','sdr','RMDs','coverage?How','This is for my hsa','pto?','A&DD','childcareplus','fs','mbi','Is that my lowesbenefit.com',\n",
    "#     'hra yes','mri?']\n",
    "# list_2 = [word.lower() for word in list_1]\n",
    "\n",
    "def text_preprocess(dataframe):\n",
    "    dataframe = dataframe.drop_duplicates()\n",
    "    dataframe[['no_of_intents', 'no_of_entities']] = dataframe.apply(lambda x: pd.Series(count_intnt_entits(x['text'])), axis=1)  \n",
    "\n",
    "    dataframe['ner_enities'] = ''\n",
    "    dataframe.loc[dataframe['text']!='', 'ner_enities'] = dataframe.loc[dataframe['text']!='', 'text'].apply(extract_ner_entities)\n",
    "    dataframe['len_ner_enities'] = dataframe['ner_enities'].apply(length_entities)\n",
    "    dataframe3 = dataframe[dataframe['len_ner_enities']>0]\n",
    "    dataframe3['text'] = dataframe3['text'].apply(filter_named_entities)\n",
    "    dataframe6 = pd.concat([dataframe[dataframe['len_ner_enities']==0], dataframe3], axis = 0)\n",
    "    dataframe6 = dataframe6.drop(['no_of_intents','no_of_entities','ner_enities','len_ner_enities'], axis=1)\n",
    "\n",
    "    dataframe6['text'] = dataframe6['text'].str.strip()\n",
    "    \n",
    "    return dataframe6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15/3440049557.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[['no_of_intents', 'no_of_entities']] = dataframe.apply(lambda x: pd.Series(count_intnt_entits(x['text'])), axis=1)\n",
      "/tmp/ipykernel_15/3440049557.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[['no_of_intents', 'no_of_entities']] = dataframe.apply(lambda x: pd.Series(count_intnt_entits(x['text'])), axis=1)\n",
      "/tmp/ipykernel_15/3440049557.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['ner_enities'] = ''\n",
      "/tmp/ipykernel_15/3440049557.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[dataframe['text']!='', 'ner_enities'] = dataframe.loc[dataframe['text']!='', 'text'].apply(extract_ner_entities)\n",
      "/tmp/ipykernel_15/3440049557.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['len_ner_enities'] = dataframe['ner_enities'].apply(length_entities)\n",
      "/tmp/ipykernel_15/3440049557.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe3['text'] = dataframe3['text'].apply(filter_named_entities)\n"
     ]
    }
   ],
   "source": [
    "df_combined_ec_model_data_2 = text_preprocess(EC_model_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6539, 3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_ec_model_data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['labels', 'text', 'category'], dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_ec_model_data_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other         4898\n",
       "Elder care    1641\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_ec_model_data_2['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_combined_ec_model_data_2.to_excel('final_ec_model_data_v6.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unseen = pd.read_excel('unseen_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WelcomeUserFollowUp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wellness Program Incentive Credit or Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medical Plan Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WelcomeUser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input\n",
       "0                                           TGT\n",
       "1                           WelcomeUserFollowUp\n",
       "2  Wellness Program Incentive Credit or Rewards\n",
       "3                           Medical Plan Credit\n",
       "4                                   WelcomeUser"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unseen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_combined_ec_model_data_2 = pd.read_excel('final_ec_model_data_v6.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     0\n",
       "labels         0\n",
       "text          12\n",
       "category       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_ec_model_data_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_combined_ec_model_data_2 = df_combined_ec_model_data_2.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hi life event need add children insurance', 'Other')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_combined_ec_model_data_2[['text', 'category']].rename(columns={'category':'label'})\n",
    "dataset = list(data.itertuples(index=False, name=None))\n",
    "\n",
    "dataset[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = []\n",
    "for text, label in dataset:\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    tokenized_dataset.append((input_ids, attention_mask, label))\n",
    "\n",
    "# Convert the tokenized dataset into PyTorch tensors\n",
    "input_ids = pad_sequence([torch.tensor(x[0]) for x in tokenized_dataset], batch_first=True)\n",
    "attention_mask = pad_sequence([torch.tensor(x[1]) for x in tokenized_dataset], batch_first=True)\n",
    "labels = torch.tensor([1 if x[2] == \"Elder care\" else 0 for x in tokenized_dataset])\n",
    "\n",
    "# Define the training parameters\n",
    "batch_size = 2\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Create the DataLoader\n",
    "dataset = torch.utils.data.TensorDataset(input_ids, attention_mask, labels)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the model, optimizer, and loss function\n",
    "model = TextClassifier(num_labels=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch {}/{} complete. Loss: {}\".format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# torch.save(model.state_dict(), \"Bert_EC_model/ec_model_10_epoch.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elder care\n"
     ]
    }
   ],
   "source": [
    "# # Use the trained model to make predictions\n",
    "# input_text = \"My grandmother needs elder care services.\"\n",
    "# input_ids = torch.tensor([tokenizer.encode(input_text, add_special_tokens=True)])\n",
    "# attention_mask = torch.tensor([[int(token_id > 0) for token_id in input_ids[0]]])\n",
    "# logits = model(input_ids, attention_mask)\n",
    "# probs = nn.functional.softmax(logits, dim=-1)\n",
    "# predicted_label = torch.argmax(probs, dim=-1)\n",
    "\n",
    "# # Print the predicted label\n",
    "# if predicted_label == 1:\n",
    "#     print(\"Elder care\")\n",
    "# else:\n",
    "#     print(\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_intnt_entits(text):\n",
    "    if str(text).isnumeric():\n",
    "        return 0,0    \n",
    "    try:\n",
    "        doc = nlp(str(text))\n",
    "        intents = [token.text for token in doc if token.pos_ == 'VERB']\n",
    "        entities = [token.text for token in doc if token.pos_ in {'NOUN', 'PROPN', 'ADJ', 'NUM', 'ADV'}]\n",
    "    except:\n",
    "        print(text)\n",
    "        raise\n",
    "    return len(intents), len(entities)\n",
    "\n",
    "def extract_ner_entities(sentence):\n",
    "    doc = nlp(str(sentence))\n",
    "    entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "    return entities\n",
    "\n",
    "def length_entities(list_entities):\n",
    "    if (list_entities==np.nan or list_entities==None or list_entities==''):\n",
    "        return 0\n",
    "    else:\n",
    "        return len(list_entities)\n",
    "    \n",
    "def filter_named_entities(text):\n",
    "    # Process the text using Spacy\n",
    "    doc = nlp(str(text))\n",
    "    # Filter out named entities (ORG, PERSON, and GPE tags)\n",
    "    filtered_words = [token.text for token in doc if token.ent_type_ not in ['ORG', 'PERSON', 'GPE', \"LOC\", \"FAC\"]]\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "def text_preprocess(col):\n",
    "    df = pd.DataFrame({ 'text': col })\n",
    "    df = df.drop_duplicates()\n",
    "    df['text'] = df['text'].str.replace('\\d+', '')\n",
    "    df[['no_of_intents', 'no_of_entities']] = df.apply(lambda x: pd.Series(count_intnt_entits(x['text'])), axis=1)  \n",
    "\n",
    "    df['ner_enities'] = ''\n",
    "    df.loc[df['text']!='', 'ner_enities'] = df.loc[df['text']!='', 'text'].apply(extract_ner_entities)\n",
    "    df['len_ner_enities'] = df['ner_enities'].apply(length_entities)\n",
    "    df3 = df[df['len_ner_enities']>0]\n",
    "    df3['text'] = df3['text'].apply(filter_named_entities)\n",
    "    df6 = pd.concat([df[df['len_ner_enities']==0], df3], axis = 0)\n",
    "    df6 = df6.drop(['no_of_intents','no_of_entities','ner_enities','len_ner_enities'], axis=1)\n",
    "\n",
    "    df6['text'] = df6['text'].str.strip()\n",
    "    \n",
    "    return df6['text'].to_list()\n",
    "\n",
    "def clean_text(text_list):\n",
    "    # Clean the text\n",
    "    text_list = text_preprocess(text_list)\n",
    "    #text_list = [text for text in text_list if text.strip() and not set(text).issubset(set(string.punctuation + string.whitespace))]\n",
    "    text_list1 = []\n",
    "    for text in text_list:\n",
    "        if isinstance(text, str):\n",
    "            if text.strip() and not set(text).issubset(set(string.punctuation + string.whitespace)):\n",
    "                text_list1.append(text)\n",
    "            \n",
    "    text_list = text_list1\n",
    "    \n",
    "    text_list = [x.lower() for x in text_list]\n",
    "    # Define a translation table to replace punctuation and special characters with empty string\n",
    "    translator = str.maketrans(string.punctuation + \"_\", \" \" * len(string.punctuation + \"_\"))\n",
    "    # Loop through each text in the list and clean it\n",
    "    cleaned_list = []\n",
    "    for text in text_list:\n",
    "        # Replace punctuation and special characters with empty string\n",
    "        cleaned_text = text.translate(translator)\n",
    "        # Remove any remaining special characters, punctuation, or whitespaces\n",
    "        cleaned_text = ' '.join(cleaned_text.split())\n",
    "        cleaned_list.append(cleaned_text)\n",
    "    \n",
    "    return cleaned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load the saved model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model.load_state_dict(torch.load(\"Bert_EC_model/ec_model_10_epoch.pth\"))\n",
    "\n",
    "# Load the input Excel file\n",
    "df = pd.read_excel('unseen_data.xlsx')\n",
    "cleaned_text_list = clean_text(df['text'].to_list())\n",
    "# Make predictions for each text in the Excel file\n",
    "predictions = []\n",
    "for text in cleaned_text_list:\n",
    "    input_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)])\n",
    "    attention_mask = torch.tensor([[int(token_id > 0) for token_id in input_ids[0]]])\n",
    "    logits = model(input_ids, attention_mask).logits\n",
    "    probs = nn.functional.softmax(logits, dim=-1)\n",
    "    predicted_label = torch.argmax(probs, dim=-1)\n",
    "    if predicted_label == 1:\n",
    "        predictions.append((text, 'Elder care', probs[0][1].item()))\n",
    "    else:\n",
    "        predictions.append((text, 'Other', probs[0][0].item()))\n",
    "\n",
    "\n",
    "# Save the predictions to a new file\n",
    "df_pred = pd.DataFrame(predictions, columns=['text', 'prediction', 'probability'])\n",
    "df_pred.to_excel('bert_ec_pred.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74027/3565708624.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace('\\d+', '')\n",
      "/tmp/ipykernel_74027/3565708624.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['text'] = df3['text'].apply(filter_named_entities)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>senior citizen care expense reimbursement</td>\n",
       "      <td>Elder care</td>\n",
       "      <td>0.999973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elderly care plus</td>\n",
       "      <td>Elder care</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aging care home</td>\n",
       "      <td>Elder care</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>retirees care reimbirsement</td>\n",
       "      <td>Elder care</td>\n",
       "      <td>0.999841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>senior assistance required</td>\n",
       "      <td>Elder care</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>daycare expense reimbursement</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baby care licensed</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.999976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oldsters care home</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.991685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contentpage eldercare subsidy</td>\n",
       "      <td>Elder care</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>elder statesmen care</td>\n",
       "      <td>Elder care</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>elder women care</td>\n",
       "      <td>Elder care</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>silver generation care</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.996034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contentpage elder care subsidy</td>\n",
       "      <td>Elder care</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gerontology care</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.931354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text  prediction  probability\n",
       "0   senior citizen care expense reimbursement  Elder care     0.999973\n",
       "1                           elderly care plus  Elder care     0.999985\n",
       "2                             aging care home  Elder care     0.999983\n",
       "3                 retirees care reimbirsement  Elder care     0.999841\n",
       "4                  senior assistance required  Elder care     0.999977\n",
       "5               daycare expense reimbursement       Other     0.999982\n",
       "6                          baby care licensed       Other     0.999976\n",
       "7                          oldsters care home       Other     0.991685\n",
       "8               contentpage eldercare subsidy  Elder care     0.999982\n",
       "9                        elder statesmen care  Elder care     0.999982\n",
       "10                           elder women care  Elder care     0.999983\n",
       "11                     silver generation care       Other     0.996034\n",
       "12             contentpage elder care subsidy  Elder care     0.999981\n",
       "13                           gerontology care       Other     0.931354"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_texts = [\"senior-citizen?care expense reimbursement\", \n",
    "                 \"elderly*care plus\",\n",
    "                 \"aging care home\", \"retirees care reimbirsement\", \n",
    "                 \"senior assistance required\",\"Daycare@expense reimbursement\",\n",
    "                 \"baby care licensed\", \"oldsters care home\",\"geriatric care home\",\n",
    "                 \"contentPage 2023 Eldercare!!!!!!!!!!!!!****@_Subsidy\",\"Elder statesmen care\",\n",
    "                 \"Elder women care\",\"Silver generation care\",\n",
    "                 \"contentPage {}[]/\\|?><,.;:!@#+\\t\\n\\r\\f\\v 2023 Elder care Subsidy\",\"gerontology care\",\n",
    "                 \"Elderly Care Plus Information\"]\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cleaned_text_list = clean_text(list_of_texts)\n",
    "\n",
    "predictions = []\n",
    "for text in cleaned_text_list:\n",
    "    # Skip empty input strings\n",
    "    if not text:\n",
    "        continue\n",
    "    input_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)])\n",
    "    attention_mask = torch.tensor([[int(token_id > 0) for token_id in input_ids[0]]])\n",
    "    token_type_ids = torch.tensor([[0] * len(input_ids[0])]) # all tokens belong to the same segment in our case\n",
    "    logits = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    predicted_label = torch.argmax(probs, dim=-1)\n",
    "    if predicted_label == 1:\n",
    "        predictions.append((text, 'Elder care', probs[0][1].item()))\n",
    "    else:\n",
    "        predictions.append((text, 'Other', probs[0][0].item()))\n",
    "\n",
    "df_pred = pd.DataFrame(predictions, columns=['text', 'prediction', 'probability'])\n",
    "df_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i need a phone number for alight</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>could pension plan selection be changed from j...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>where do i add my bank deposit info</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>virgin pluse</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>why att sent me enroll sheet</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text category\n",
       "0           0                   i need a phone number for alight    Other\n",
       "1           1  could pension plan selection be changed from j...    Other\n",
       "2           2                where do i add my bank deposit info    Other\n",
       "3           3                                       virgin pluse    Other\n",
       "4           4                       why att sent me enroll sheet    Other"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SequenceClassifierOutput' object has no attribute 'softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_ids[\u001b[38;5;241m0\u001b[39m])]) \u001b[38;5;66;03m# all tokens belong to the same segment in our case\u001b[39;00m\n\u001b[1;32m     20\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids)\n\u001b[0;32m---> 22\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(probs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predicted_label \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py:1841\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1839\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1841\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m(dim)\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1843\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SequenceClassifierOutput' object has no attribute 'softmax'"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model.load_state_dict(torch.load(\"Bert_EC_model/ec_model_10_epoch.pth\"))\n",
    "\n",
    "# Load the input Excel file\n",
    "df = pd.read_excel('labelled_unseen_data.xlsx')\n",
    "cleaned_text_list = df['text'].to_list()\n",
    "category_list = df['category'].to_list()\n",
    "\n",
    "# Make predictions for each text in the Excel file\n",
    "predictions = []\n",
    "for i in range(len(cleaned_text_list)):\n",
    "    text = cleaned_text_list[i]\n",
    "    category = category_list[i]\n",
    "    input_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)])\n",
    "    attention_mask = torch.tensor([[int(token_id > 0) for token_id in input_ids[0]]])\n",
    "    logits = model(input_ids, attention_mask).logits\n",
    "    probs = nn.functional.softmax(logits, dim=-1)\n",
    "    predicted_label = torch.argmax(probs, dim=-1)\n",
    "    if predicted_label == 1:\n",
    "        predictions.append((text, 'Elder care', category, probs[0][1].item()))\n",
    "    else:\n",
    "        predictions.append((text, 'Other', category, probs[0][0].item()))\n",
    "\n",
    "# Save the predictions to a new file\n",
    "df_pred = pd.DataFrame(predictions, columns=['text', 'prediction', 'category', 'probability'])\n",
    "df_pred.to_excel('bert_labelled_ec_pred.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert saved model .bin and config.json to .pkl compatible files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert saved model .bin and config.json to .pkl compatible files\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Load the model configuration from the config.json file\n",
    "config = AutoConfig.from_pretrained('EC_model_outer_combined_texts_data_v6', num_labels=2)\n",
    "\n",
    "# Load the model from the binary file using the configuration\n",
    "model = AutoModelForSequenceClassification.from_pretrained('EC_model_outer_combined_texts_data_v6', config=config)\n",
    "\n",
    "# Save the model and configuration as a pickle file\n",
    "with open('EC_model_outer_combined_texts_data_v6/EC_model.pkl', 'wb') as f:\n",
    "    pickle.dump((config, model.state_dict()), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tagging the unseen_data for analysisng the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding the texts which contain exact phrases from synonyms list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_3 = ['older parent','older people','grand parents','elder','old parents','elder women',\n",
    " 'silver generation','aged people', 'older women','older men','old age home','elder',\n",
    " 'aged',\n",
    " 'elderly people',\n",
    " 'senior assistance',\n",
    " 'aging-in-place',\n",
    " 'aged population',\n",
    " 'golden agers',\n",
    " 'aging in place',\n",
    " 'grey generation',\n",
    " 'silver generation',\n",
    " 'senior health',\n",
    " 'aged population',\n",
    " 'elderly companion',\n",
    " 'golden agers',\n",
    " 'senior citizen',\n",
    " 'elder support',\n",
    " 'elderly',\n",
    " 'senior members',\n",
    " 'elder population',\n",
    " 'elderly residents',\n",
    " 'senior assistance',\n",
    " 'oldsters',\n",
    " 'grey generation',\n",
    " 'aging population',\n",
    " 'elder statesmen',\n",
    " 'elderly',\n",
    " 'elderly people',\n",
    " 'aging',\n",
    " 'elderly residents',\n",
    " 'elder',\n",
    " 'elder women',\n",
    " 'senior',\n",
    " 'elder generation',\n",
    " 'gerontology',\n",
    " 'elderly population',\n",
    " 'senior members',\n",
    " 'retirees',\n",
    " 'elderly population',\n",
    " 'eldercare',\n",
    " 'geriatric',\n",
    " 'elder statesmen',\n",
    " 'age related',\n",
    " 'retirees',\n",
    " 'third age population',\n",
    " 'aging population',\n",
    " 'elder population',\n",
    " 'oldsters',\n",
    " 'third age population','eldercae', 'eldercarr', 'eldermann', \n",
    "'aged home','eldercre','eldery','elderman','elders','eldercrae',]\n",
    "words_4 = list(set([word.lower() for word in words_3]))\n",
    "len(words_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcomeuserfollowup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medical plan credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>welcomeuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>general purpose loans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chiropractor visits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text\n",
       "0    welcomeuserfollowup\n",
       "1    medical plan credit\n",
       "2            welcomeuser\n",
       "3  general purpose loans\n",
       "4    chiropractor visits"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = pd.DataFrame()\n",
    "df_cleaned['text'] =cleaned_text_list\n",
    "df_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74027/3427755096.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = (df_cleaned['text'].str.contains(r'\\b(' + '|'.join(words_4) + r')\\b', case=False, na=False))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcomeuserfollowup</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medical plan credit</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>welcomeuser</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>general purpose loans</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chiropractor visits</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text category\n",
       "0    welcomeuserfollowup         \n",
       "1    medical plan credit         \n",
       "2            welcomeuser         \n",
       "3  general purpose loans         \n",
       "4    chiropractor visits         "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_cleaned['text'].str.contains(r'\\b(' + '|'.join(words_4) + r')\\b', case=False, na=False))\n",
    "\n",
    "df_cleaned['category'] = ''\n",
    "df_cleaned.loc[mask, 'category'] = 'Elder care'\n",
    "# df_combined_web_iva_search.loc[df_combined_web_iva_search['category'] == '', 'category'] = 'Other'\n",
    "\n",
    "df_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>ongoing elderly care</td>\n",
       "      <td>Elder care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      text    category\n",
       "5666  ongoing elderly care  Elder care"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned[df_cleaned['category']=='Elder care'].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned[df_cleaned['category']=='Elder care'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get text which are similar to phrases in synonnyms list for texts other than which are filtered above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_sentences(df, sentences, phrases, threshold=0.95, category_name = 'Elder care'):\n",
    "    # encode the phrases using the model\n",
    "    phrase_embeddings = model.encode(phrases, convert_to_tensor=True)\n",
    "    \n",
    "    # initialize an empty list to store the similar sentences\n",
    "    similar_sentences = []\n",
    "    \n",
    "    # iterate over the sentences\n",
    "    for sentence in sentences:\n",
    "        # encode the sentence using the model\n",
    "        sentence_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "        # reshape the sentence embedding to a 2D array\n",
    "        sentence_embedding = sentence_embedding.reshape(1, -1)\n",
    "        \n",
    "        # calculate the cosine similarity between the sentence embedding and each phrase embedding\n",
    "        cosine_scores = 1 - cosine_distances(sentence_embedding, phrase_embeddings)\n",
    "        \n",
    "        # convert the cosine similarity scores to a list\n",
    "        scores_list = cosine_scores.tolist()[0]\n",
    "        \n",
    "        # iterate over the phrases and similarity scores and append the sentence to the list if it meets the threshold for at least one phrase\n",
    "        for phrase, score in zip(phrases, scores_list):\n",
    "            if score >= threshold:\n",
    "                similar_sentences.append(sentence)\n",
    "                break\n",
    "    \n",
    "    # convert the list of similar sentences to a set to remove duplicates\n",
    "    similar_sentences = set(similar_sentences)\n",
    "    \n",
    "    # create a new dataframe containing only the rows with text that is in the set of similar sentences\n",
    "    similar_df = df[df['text'].isin(similar_sentences)]\n",
    "    similar_df['category']=category_name\n",
    "    return similar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74027/2749835889.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_df['category']=category_name\n"
     ]
    }
   ],
   "source": [
    "similar_df_unseen = find_similar_sentences(df_cleaned, \n",
    "                                    df_cleaned[df_cleaned['category']=='']['text'].to_list(), \n",
    "                                    words_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7095</th>\n",
       "      <td>retiremen</td>\n",
       "      <td>Elder care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text    category\n",
       "7095  retiremen  Elder care"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_df_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_EC_df = pd.concat([df_cleaned[df_cleaned['category']=='Elder care'], \n",
    "                       similar_df_unseen]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_EC_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_EC_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_EC_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74027/3802977147.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_similar_unseen_df['category'] = 'Other'\n"
     ]
    }
   ],
   "source": [
    "# filter out the rows with similar text from the original DataFrame\n",
    "non_similar_unseen_df = df_cleaned[~df_cleaned['text'].isin(unseen_EC_df['text'])]\n",
    "\n",
    "# sample twice as many rows from the non-similar DataFrame as there are in the similar DataFrame\n",
    "# non_similar_df = non_similar_df.sample(n=only_EC_df.shape[0]*2)\n",
    "non_similar_unseen_df['category'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unseen_concatenated = pd.concat([unseen_EC_df, non_similar_unseen_df]).sample(frac=1).reset_index(drop=True)\n",
    "# df_concatenated = df_concatenated\n",
    "# df_concatenated.drop(columns=['input', 'search_text', 'page_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12584, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unseen_concatenated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unseen_concatenated[(df_unseen_concatenated.text.str.contains('elder')) & (df_unseen_concatenated.category=='Other')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unseen_concatenated.to_excel('labelled_unseen_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.r5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
