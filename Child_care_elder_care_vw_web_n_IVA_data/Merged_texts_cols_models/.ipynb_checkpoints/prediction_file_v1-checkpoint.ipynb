{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1235953-4709-47c6-a484-c61e70359a8f",
   "metadata": {},
   "source": [
    "# prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2deaf2a-5472-4137-a3c4-9afbfbd9e8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f63f6720-b44b-4921-937a-15ce3ba9cf46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "# import s3fs\n",
    "import joblib\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "nltk.data.path.append('../../nltk_data')\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5153a-b45c-4194-8ccb-f5151bae9f95",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a80ac72d-a243-40a4-8936-547afa146837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the S3 bucket and prefix where the Parquet files are stored\n",
    "# s3://adl-core-sagemaker-studio/external/IVA/IVA_daily/\n",
    "# s3://adl-core-sagemaker-studio/external/IVA/Search_daily/\n",
    "# s3://adl-core-sagemaker-studio/external/Deepali/iva-data(3-apr).csv\n",
    "# s3://adl-core-sagemaker-studio/external/Deepali/search_data/\n",
    "\n",
    "# model_path = 'Bert_EC_model/ec_model_v1.pkl'\n",
    "model_path = 'Bert_CC_model/cc_model_v1.joblib'\n",
    "\n",
    "bucket_name = 'adl-core-sagemaker-studio'\n",
    "# prefix = 'external/web_clickstream/clickstream20230403_20230403/'\n",
    "prefix = 'external/Deepali/search_data/'\n",
    "\n",
    "# words_3 = ['elder','elder women','elder','Octogenarians','Nonagenarians','Centenarians',\n",
    "# 'elderly people',\n",
    "#  'senior assistance',\n",
    "#  'grey generation',\n",
    "#  'senior health',\n",
    "#  'elderly companion',\n",
    "#  'senior citizen',\n",
    "#  'elderly',\n",
    "#  'senior members',\n",
    "#  'elderly residents',\n",
    "#  'senior assistance',\n",
    "#  'grey generation',\n",
    "#  'elder',\n",
    "#  'elderly',\n",
    "#  'elderly people',\n",
    "#  'elderly residents',\n",
    "#  'elder',\n",
    "#  'elder',\n",
    "#  'senior citizen',\n",
    "#  'elder generation',\n",
    "#  'gerontology',\n",
    "#  'elderly population',\n",
    "#  'senior members',\n",
    "#  'retirees',\n",
    "#  'elderly population',\n",
    "#  'eldercare',\n",
    "#  'elder',\n",
    "# 'eldercae', 'eldercarr', 'eldermann',\n",
    "# 'eldercre','eldery','elderman','elders','eldercrae']\n",
    "# words_3 = ['day care', 'creche', 'childcare', 'daycare', 'after school care', 'pre school', 'child', 'baby',\n",
    "#            'infant', 'girl child', 'play school', 'boy child', 'Adolescent', 'nursery', 'preschool', 'day nursery',\n",
    "#            'playschool', 'kindergarten', 'childminding', 'babysitting', 'babysitter', 'nanny', 'children supervision', \n",
    "#            'toddler care', 'baby sitter', 'children', 'child supervision', 'childs', 'stepchild', 'step daughter', 'step son', \n",
    "#            'grandchildren', 'grandchild', 'daughter', 'son', 'stepchildren', 'childhood', 'day cares', 'childrent', 'daycares', \n",
    "#            'childplus']\n",
    "\n",
    "# words_4 = set([word.lower() for word in words_3])\n",
    "sent_trans_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "# len(words_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e632d839-7679-4669-a973-f07d1a3e5a94",
   "metadata": {},
   "source": [
    "# Inferencing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "909cdb3e-c0e1-4243-a118-3402260a1e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def fetch_data_from_s3(text_col):\n",
    "#     # Initialize S3 client\n",
    "#     s3 = boto3.client('s3')\n",
    "    \n",
    "#     # List all Parquet files in the bucket with the specified prefix\n",
    "#     response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "#     if 'Contents' in response:\n",
    "#         # parquet_files = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith('.parq')]\n",
    "#         csv_files = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith('.csv')]\n",
    "#     else:\n",
    "#         # parquet_files = []\n",
    "#         csv_files = []\n",
    "\n",
    "#     # Read Parquet files and concatenate them together\n",
    "#     dfs = []\n",
    "#     #s3fs = s3fs.S3FileSystem()\n",
    "\n",
    "#     # for file in parquet_files:\n",
    "#     for file in csv_files:\n",
    "#         # Read the Parquet file into a PyArrow table\n",
    "#         s3_key = f\"{bucket_name}/{file}\"\n",
    "#         # dataset = pq.ParquetDataset(f\"s3://{s3_key}\", filesystem=s3fs)\n",
    "#         df = pd.read_csv(f\"s3://{s3_key}\")\n",
    "#         # table = dataset.read()\n",
    "\n",
    "#         # Convert the PyArrow table to a Pandas DataFrame\n",
    "#         # df = table.to_pandas()\n",
    "#         # print(df.head())\n",
    "#         dfs.append(df)\n",
    "\n",
    "#     # # Concatenate all the DataFrames together\n",
    "#     # try:\n",
    "#     #     concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "#     #     #print(concatenated_df.head())\n",
    "#     # except:\n",
    "#     #     # print(\"No Parquet files found.\")\n",
    "#     #     print(\"No csv files found.\")\n",
    "#     #     raise\n",
    "#     if len(dfs) == 0:\n",
    "#         raise ValueError(\"No DataFrame provided.\")\n",
    "#     elif len(dfs) == 1:\n",
    "#         return dfs[0]\n",
    "#     else:\n",
    "#         try:\n",
    "#             concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "#             return concatenated_df\n",
    "#         except:\n",
    "#             raise ValueError(\"Error occurred while concatenating DataFrames.\")\n",
    "        \n",
    "#     # concatenated_df= concatenated_df[['client_id','person_internal_id','page_name']]\n",
    "#     concatenated_df= concatenated_df[['client_id','person_internal_id', text_col]]\n",
    "        \n",
    "#     return concatenated_df\n",
    "\n",
    "def read_dataframe_from_s3(file_path):\n",
    "    if file_path.endswith(\".parquet\"):\n",
    "        # Initialize S3 client\n",
    "        s3 = boto3.client('s3')\n",
    "        s3fs = s3fs.S3FileSystem()\n",
    "\n",
    "        # Read the Parquet file into a PyArrow table\n",
    "        dataset = pq.ParquetDataset(f\"s3://{file_path}\", filesystem=s3fs)\n",
    "        table = dataset.read()\n",
    "\n",
    "        # Convert the PyArrow table to a Pandas DataFrame\n",
    "        df = table.to_pandas()\n",
    "        return df\n",
    "    elif file_path.endswith(\".csv\"):\n",
    "        # Initialize S3 client\n",
    "        s3 = boto3.client('s3')\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(f\"s3://{file_path}\")\n",
    "        return df\n",
    "    elif file_path.endswith(\".xlsx\"):\n",
    "        # Initialize S3 client\n",
    "        s3 = boto3.client('s3')\n",
    "        \n",
    "        # Read the Excel file into a DataFrame\n",
    "        df = pd.read_excel(f\"s3://{file_path}\")\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Only .parquet, .csv, and .xlsx are supported.\")\n",
    "\n",
    "def fetch_data_from_s3(bucket_name, prefix, text_col):\n",
    "    # Initialize S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # List all Parquet, CSV, and Excel files in the bucket with the specified prefix\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "    # Check if the response contains any objects\n",
    "    if 'Contents' not in response:\n",
    "        print(\"No DataFrame provided.\")\n",
    "        return None\n",
    "\n",
    "    file_paths = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith(('.parquet', '.csv', '.xlsx'))]\n",
    "\n",
    "    # Read files and concatenate them together\n",
    "    dfs = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            df = read_dataframe_from_s3(file_path)\n",
    "            dfs.append(df)\n",
    "        except:\n",
    "            print(f\"Failed to read {file_path}. Skipping.\")\n",
    "\n",
    "    if len(dfs) == 0:\n",
    "        print(\"No DataFrame provided.\")\n",
    "        return None\n",
    "    elif len(dfs) == 1:\n",
    "        return dfs[0]\n",
    "    else:\n",
    "        try:\n",
    "            concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "            concatenated_df = concatenated_df[['client_id', 'person_internal_id', text_col]]\n",
    "            return concatenated_df\n",
    "        except:\n",
    "            raise ValueError(\"Error occurred while concatenating DataFrames.\")\n",
    "\n",
    "\n",
    "def clean_text(df, text_cols):\n",
    "    if df is None or df.empty:\n",
    "        print(\"No DataFrame provided.\")\n",
    "        return pd.DataFrame()\n",
    "    # Create a new dataframe to hold the cleaned text columns\n",
    "    cleaned_df = pd.DataFrame()\n",
    "    \n",
    "    # Define the list of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Clean each text column and add it to the cleaned dataframe\n",
    "    for text_col in text_cols:\n",
    "        text_list = df[text_col].tolist()\n",
    "        text_list = [str(text) for text in text_list]\n",
    "        text_list = [text if text.strip() and not\n",
    "                     set(text).issubset(set(string.punctuation + string.whitespace)) else '' \n",
    "                     for text in text_list]\n",
    "        text_list = [x.lower() for x in text_list]\n",
    "        translator = str.maketrans(string.punctuation + string.digits + \"_\", \" \" * len(\n",
    "            string.punctuation + string.digits + \"_\"))\n",
    "        cleaned_list = []\n",
    "        for text in text_list:\n",
    "            cleaned_text = text.translate(translator)\n",
    "            cleaned_text = ' '.join(cleaned_text.split())\n",
    "            cleaned_text = ' '.join([word for word in cleaned_text.split() if word not in stop_words])\n",
    "            cleaned_list.append(cleaned_text)\n",
    "        cleaned_df[text_col] = cleaned_list\n",
    "    \n",
    "    # Add the non-text columns to the cleaned dataframe\n",
    "    for col in df.columns:\n",
    "        if col not in text_cols:\n",
    "            cleaned_df[col] = df[col]\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "def predict(df, text_col, category_name, threshold):\n",
    "    # Load the model\n",
    "    classifier = joblib.load(model_path)\n",
    "    \n",
    "    # Encode the text samples from the Parquet file\n",
    "    encodings = sent_trans_model.encode(df[text_col].fillna(' ').tolist())\n",
    "\n",
    "    # Make predictions for the encoded samples\n",
    "    # predictions = loaded_model.predict(encodings)\n",
    "    probabilities = classifier.predict_proba(encodings)\n",
    "    \n",
    "    # Apply threshold and assign labels\n",
    "    df['predicted_label'] = np.where(probabilities[:, 0] > threshold, category_name, 'Other')\n",
    "    df['prediction'] = df['predicted_label'].map({category_name:1, 'Other':0})\n",
    "    \n",
    "    df['pred_probab'] = probabilities[:, 0]\n",
    "    \n",
    "    # Save the predictions in an Excel file\n",
    "    df[['client_id','person_internal_id', text_col, 'predicted_label', 'prediction', 'pred_probab']].to_csv(f'{category_name}_{text_col}_predictions.csv', index=False)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(elapsed_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b3866-ec46-4314-b29a-854e844a797f",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87b09deb-74c2-45a0-a994-4924fbde02fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_prediction_pipeline(text_col, category_name, threshold):    \n",
    "    df =  fetch_data_from_s3(bucket_name, prefix, text_col)\n",
    "\n",
    "    # cleaned_concatenated_df = clean_text(concatenated_df, text_cols=['page_name'])\n",
    "    cleaned_concatenated_df = clean_text(df, text_cols=[text_col])\n",
    "    \n",
    "    predict(cleaned_concatenated_df, text_col, category_name, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e5a3778-e84e-4556-90f5-3e8f3692165c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read external/Deepali/search_data/search-data(3-apr).csv. Skipping.\n",
      "No DataFrame provided.\n",
      "No DataFrame provided.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'search_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'search_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#threshold for cc for f1 score =1 is 0.999\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#threshold for ec for f1 score =0.97913 is 0.485\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mrun_prediction_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearch_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcategory_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mChild care\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36mrun_prediction_pipeline\u001b[0;34m(text_col, category_name, threshold)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# cleaned_concatenated_df = clean_text(concatenated_df, text_cols=['page_name'])\u001b[39;00m\n\u001b[1;32m      5\u001b[0m cleaned_concatenated_df \u001b[38;5;241m=\u001b[39m clean_text(df, text_cols\u001b[38;5;241m=\u001b[39m[text_col])\n\u001b[0;32m----> 7\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_concatenated_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(df, text_col, category_name, threshold)\u001b[0m\n\u001b[1;32m    159\u001b[0m classifier \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Encode the text samples from the Parquet file\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m encodings \u001b[38;5;241m=\u001b[39m sent_trans_model\u001b[38;5;241m.\u001b[39mencode(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Make predictions for the encoded samples\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# predictions = loaded_model.predict(encodings)\u001b[39;00m\n\u001b[1;32m    166\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict_proba(encodings)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'search_text'"
     ]
    }
   ],
   "source": [
    "#threshold for cc for f1 score =1 is 0.999\n",
    "#threshold for ec for f1 score =0.97913 is 0.485\n",
    "if __name__ == \"__main__\":\n",
    "    run_prediction_pipeline(text_col = 'search_text', \n",
    "                            category_name='Child care' , threshold= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798fa51b-8c7e-4400-9121-3beb2227077e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b3c1c-a45e-4d37-a787-843b74f7c920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd1066-6ac0-46b0-a46e-9294b9d92bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df796a-dc34-4b99-bbb7-d34e6c54e0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5d.24xlarge",
  "kernelspec": {
   "display_name": "python3 (adl-core-custom-docker/1)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:660999144548:image-version/adl-core-custom-docker/1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
