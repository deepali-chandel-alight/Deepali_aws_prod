{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install en_core_web_sm-3.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 00:39:55.525588: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/1765538524.py:1: DtypeWarning: Columns (0,1,2,4,5,9,10,11,12,13,14,15,16,17,18,20,21,23,24,25,26,27,28,29,31,33,39,41,56,57,58,59,63,64,65,67,68,70,71,74,75,77,78,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,106,108,109,110,111,112,113,114,115,116,117,118,119,122,123,124,125,126,127,128,129,130,131,132,134,135,136,137,138,155,156,159,160,161,164,165) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_combined_web_iva_search = pd.read_csv(\"s3://adl-core-sagemaker-studio/external/IVA/combined_new_adult-child_outer_new.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_combined_web_iva_search = pd.read_csv(\"s3://adl-core-sagemaker-studio/external/IVA/combined_new_adult-child_outer_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_web_iva_search['session_start_cst'] = pd.to_datetime(df_combined_web_iva_search['session_start_cst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-09-16 10:00:50')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_web_iva_search['session_start_cst'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-03-26 22:31:18')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_web_iva_search['session_start_cst'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1245878, 170)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_web_iva_search.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_web_iva_search.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1106709, 170)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_web_iva_search.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_counts_1 = df_combined_web_iva_search.resample('M', on='session_start_cst').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_entitlement_client_name</th>\n",
       "      <th>agent_entitlement_access_key</th>\n",
       "      <th>channel</th>\n",
       "      <th>companytracking_clientid</th>\n",
       "      <th>companytracking_companyid</th>\n",
       "      <th>companytracking_companyname</th>\n",
       "      <th>companytracking_multitenantid</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>entry_order</th>\n",
       "      <th>entry_type</th>\n",
       "      <th>...</th>\n",
       "      <th>load_timestamp</th>\n",
       "      <th>source_system_code</th>\n",
       "      <th>mobile_app_device_type</th>\n",
       "      <th>page_load_elapsed_time</th>\n",
       "      <th>mobile_app_type</th>\n",
       "      <th>session_create_date_cst_timezone_partition</th>\n",
       "      <th>platform_id_y</th>\n",
       "      <th>search_text</th>\n",
       "      <th>search_results</th>\n",
       "      <th>session_created_timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_start_cst</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>431</td>\n",
       "      <td>431</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>4733</td>\n",
       "      <td>4733</td>\n",
       "      <td>4733</td>\n",
       "      <td>4733</td>\n",
       "      <td>4733</td>\n",
       "      <td>4733</td>\n",
       "      <td>0</td>\n",
       "      <td>4733</td>\n",
       "      <td>4733</td>\n",
       "      <td>4733</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30</th>\n",
       "      <td>4571</td>\n",
       "      <td>4571</td>\n",
       "      <td>4571</td>\n",
       "      <td>4571</td>\n",
       "      <td>4571</td>\n",
       "      <td>4571</td>\n",
       "      <td>0</td>\n",
       "      <td>4571</td>\n",
       "      <td>4571</td>\n",
       "      <td>4571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>783</td>\n",
       "      <td>783</td>\n",
       "      <td>783</td>\n",
       "      <td>783</td>\n",
       "      <td>783</td>\n",
       "      <td>783</td>\n",
       "      <td>0</td>\n",
       "      <td>783</td>\n",
       "      <td>783</td>\n",
       "      <td>783</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31</th>\n",
       "      <td>1290</td>\n",
       "      <td>1290</td>\n",
       "      <td>1289</td>\n",
       "      <td>1290</td>\n",
       "      <td>1290</td>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "      <td>1290</td>\n",
       "      <td>1290</td>\n",
       "      <td>1290</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>25689</td>\n",
       "      <td>25689</td>\n",
       "      <td>25685</td>\n",
       "      <td>25689</td>\n",
       "      <td>25688</td>\n",
       "      <td>25688</td>\n",
       "      <td>0</td>\n",
       "      <td>25689</td>\n",
       "      <td>25689</td>\n",
       "      <td>25689</td>\n",
       "      <td>...</td>\n",
       "      <td>21823</td>\n",
       "      <td>21823</td>\n",
       "      <td>0</td>\n",
       "      <td>21793</td>\n",
       "      <td>21823</td>\n",
       "      <td>21823</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>24983</td>\n",
       "      <td>24983</td>\n",
       "      <td>24981</td>\n",
       "      <td>24983</td>\n",
       "      <td>24980</td>\n",
       "      <td>24980</td>\n",
       "      <td>0</td>\n",
       "      <td>24983</td>\n",
       "      <td>24983</td>\n",
       "      <td>24983</td>\n",
       "      <td>...</td>\n",
       "      <td>23144</td>\n",
       "      <td>23144</td>\n",
       "      <td>0</td>\n",
       "      <td>23122</td>\n",
       "      <td>23144</td>\n",
       "      <td>23144</td>\n",
       "      <td>9085</td>\n",
       "      <td>9085</td>\n",
       "      <td>9085</td>\n",
       "      <td>9085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>47121</td>\n",
       "      <td>47121</td>\n",
       "      <td>47120</td>\n",
       "      <td>47121</td>\n",
       "      <td>47118</td>\n",
       "      <td>47118</td>\n",
       "      <td>0</td>\n",
       "      <td>47121</td>\n",
       "      <td>47121</td>\n",
       "      <td>47121</td>\n",
       "      <td>...</td>\n",
       "      <td>44577</td>\n",
       "      <td>44577</td>\n",
       "      <td>0</td>\n",
       "      <td>44512</td>\n",
       "      <td>44577</td>\n",
       "      <td>44577</td>\n",
       "      <td>20052</td>\n",
       "      <td>20052</td>\n",
       "      <td>20052</td>\n",
       "      <td>20052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>27164</td>\n",
       "      <td>27164</td>\n",
       "      <td>27163</td>\n",
       "      <td>27164</td>\n",
       "      <td>27163</td>\n",
       "      <td>27163</td>\n",
       "      <td>0</td>\n",
       "      <td>27164</td>\n",
       "      <td>27164</td>\n",
       "      <td>27164</td>\n",
       "      <td>...</td>\n",
       "      <td>25345</td>\n",
       "      <td>25345</td>\n",
       "      <td>0</td>\n",
       "      <td>25304</td>\n",
       "      <td>25345</td>\n",
       "      <td>25345</td>\n",
       "      <td>9381</td>\n",
       "      <td>9381</td>\n",
       "      <td>9381</td>\n",
       "      <td>9381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>22109</td>\n",
       "      <td>22109</td>\n",
       "      <td>22107</td>\n",
       "      <td>22109</td>\n",
       "      <td>22103</td>\n",
       "      <td>22103</td>\n",
       "      <td>0</td>\n",
       "      <td>22109</td>\n",
       "      <td>22109</td>\n",
       "      <td>22109</td>\n",
       "      <td>...</td>\n",
       "      <td>19186</td>\n",
       "      <td>19186</td>\n",
       "      <td>0</td>\n",
       "      <td>19143</td>\n",
       "      <td>19186</td>\n",
       "      <td>19186</td>\n",
       "      <td>7420</td>\n",
       "      <td>7420</td>\n",
       "      <td>7420</td>\n",
       "      <td>7420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   agent_entitlement_client_name  \\\n",
       "session_start_cst                                  \n",
       "2017-09-30                                   442   \n",
       "2017-10-31                                  4733   \n",
       "2017-11-30                                  4571   \n",
       "2017-12-31                                   783   \n",
       "2018-01-31                                  1290   \n",
       "...                                          ...   \n",
       "2022-11-30                                 25689   \n",
       "2022-12-31                                 24983   \n",
       "2023-01-31                                 47121   \n",
       "2023-02-28                                 27164   \n",
       "2023-03-31                                 22109   \n",
       "\n",
       "                   agent_entitlement_access_key  channel  \\\n",
       "session_start_cst                                          \n",
       "2017-09-30                                  442      442   \n",
       "2017-10-31                                 4733     4733   \n",
       "2017-11-30                                 4571     4571   \n",
       "2017-12-31                                  783      783   \n",
       "2018-01-31                                 1290     1289   \n",
       "...                                         ...      ...   \n",
       "2022-11-30                                25689    25685   \n",
       "2022-12-31                                24983    24981   \n",
       "2023-01-31                                47121    47120   \n",
       "2023-02-28                                27164    27163   \n",
       "2023-03-31                                22109    22107   \n",
       "\n",
       "                   companytracking_clientid  companytracking_companyid  \\\n",
       "session_start_cst                                                        \n",
       "2017-09-30                              442                        431   \n",
       "2017-10-31                             4733                       4733   \n",
       "2017-11-30                             4571                       4571   \n",
       "2017-12-31                              783                        783   \n",
       "2018-01-31                             1290                       1290   \n",
       "...                                     ...                        ...   \n",
       "2022-11-30                            25689                      25688   \n",
       "2022-12-31                            24983                      24980   \n",
       "2023-01-31                            47121                      47118   \n",
       "2023-02-28                            27164                      27163   \n",
       "2023-03-31                            22109                      22103   \n",
       "\n",
       "                   companytracking_companyname  companytracking_multitenantid  \\\n",
       "session_start_cst                                                               \n",
       "2017-09-30                                 431                              0   \n",
       "2017-10-31                                4733                              0   \n",
       "2017-11-30                                4571                              0   \n",
       "2017-12-31                                 783                              0   \n",
       "2018-01-31                                1290                              0   \n",
       "...                                        ...                            ...   \n",
       "2022-11-30                               25688                              0   \n",
       "2022-12-31                               24980                              0   \n",
       "2023-01-31                               47118                              0   \n",
       "2023-02-28                               27163                              0   \n",
       "2023-03-31                               22103                              0   \n",
       "\n",
       "                   entry_id  entry_order  entry_type  ...  load_timestamp  \\\n",
       "session_start_cst                                     ...                   \n",
       "2017-09-30              442          442         442  ...               0   \n",
       "2017-10-31             4733         4733        4733  ...               0   \n",
       "2017-11-30             4571         4571        4571  ...               0   \n",
       "2017-12-31              783          783         783  ...               0   \n",
       "2018-01-31             1290         1290        1290  ...              36   \n",
       "...                     ...          ...         ...  ...             ...   \n",
       "2022-11-30            25689        25689       25689  ...           21823   \n",
       "2022-12-31            24983        24983       24983  ...           23144   \n",
       "2023-01-31            47121        47121       47121  ...           44577   \n",
       "2023-02-28            27164        27164       27164  ...           25345   \n",
       "2023-03-31            22109        22109       22109  ...           19186   \n",
       "\n",
       "                   source_system_code  mobile_app_device_type  \\\n",
       "session_start_cst                                               \n",
       "2017-09-30                          0                       0   \n",
       "2017-10-31                          0                       0   \n",
       "2017-11-30                          0                       0   \n",
       "2017-12-31                          0                       0   \n",
       "2018-01-31                         36                       0   \n",
       "...                               ...                     ...   \n",
       "2022-11-30                      21823                       0   \n",
       "2022-12-31                      23144                       0   \n",
       "2023-01-31                      44577                       0   \n",
       "2023-02-28                      25345                       0   \n",
       "2023-03-31                      19186                       0   \n",
       "\n",
       "                   page_load_elapsed_time  mobile_app_type  \\\n",
       "session_start_cst                                            \n",
       "2017-09-30                              0                0   \n",
       "2017-10-31                              0                0   \n",
       "2017-11-30                              0                0   \n",
       "2017-12-31                              0                0   \n",
       "2018-01-31                             36               36   \n",
       "...                                   ...              ...   \n",
       "2022-11-30                          21793            21823   \n",
       "2022-12-31                          23122            23144   \n",
       "2023-01-31                          44512            44577   \n",
       "2023-02-28                          25304            25345   \n",
       "2023-03-31                          19143            19186   \n",
       "\n",
       "                   session_create_date_cst_timezone_partition  platform_id_y  \\\n",
       "session_start_cst                                                              \n",
       "2017-09-30                                                  0              0   \n",
       "2017-10-31                                                  0              0   \n",
       "2017-11-30                                                  0              0   \n",
       "2017-12-31                                                  0              0   \n",
       "2018-01-31                                                 36              1   \n",
       "...                                                       ...            ...   \n",
       "2022-11-30                                              21823           9000   \n",
       "2022-12-31                                              23144           9085   \n",
       "2023-01-31                                              44577          20052   \n",
       "2023-02-28                                              25345           9381   \n",
       "2023-03-31                                              19186           7420   \n",
       "\n",
       "                   search_text  search_results  session_created_timestamp  \n",
       "session_start_cst                                                          \n",
       "2017-09-30                   0               0                          0  \n",
       "2017-10-31                   0               0                          0  \n",
       "2017-11-30                   0               0                          0  \n",
       "2017-12-31                   0               0                          0  \n",
       "2018-01-31                   1               1                          1  \n",
       "...                        ...             ...                        ...  \n",
       "2022-11-30                9000            9000                       9000  \n",
       "2022-12-31                9085            9085                       9085  \n",
       "2023-01-31               20052           20052                      20052  \n",
       "2023-02-28                9381            9381                       9381  \n",
       "2023-03-31                7420            7420                       7420  \n",
       "\n",
       "[67 rows x 170 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_counts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_web_iva_search2 = df_combined_web_iva_search[['input', 'session_id','person_internal_id',\n",
    "'client_id','yyyymm','person_id','person_birth_date', 'person_age', 'person_gender', \n",
    "'person_employment_status','person_state', 'person_union_vs_non_union', 'person_salary',\n",
    "'person_eeo',\n",
    "'global_session_id',\n",
    "'web_session_id',\n",
    "'page_name',\n",
    "'business_page_name',\n",
    "'page_domain',\n",
    "'page_type_code',\n",
    "'page_type',\n",
    "'page_web_type_description',\n",
    "'browser_language',\n",
    "'page_visit_duration',\n",
    "'page_process_name',\n",
    "'page_process_detail',\n",
    " 'session_start_cst',                                                         \n",
    "'search_text',\n",
    "'search_results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_web_iva_search3 = df_combined_web_iva_search2.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['input', 'session_id', 'person_internal_id', 'client_id', 'yyyymm',\n",
       "       'person_id', 'person_birth_date', 'person_age', 'person_gender',\n",
       "       'person_employment_status', 'person_state', 'person_union_vs_non_union',\n",
       "       'person_salary', 'person_eeo', 'global_session_id', 'web_session_id',\n",
       "       'page_name', 'business_page_name', 'page_domain', 'page_type_code',\n",
       "       'page_type', 'page_web_type_description', 'browser_language',\n",
       "       'page_visit_duration', 'page_process_name', 'page_process_detail',\n",
       "       'session_start_cst', 'search_text', 'search_results'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_web_iva_search3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_2 = ['day care', 'creche', 'child care', \n",
    " 'nursery', 'nursery school', 'preschool', 'after-school care', 'day nursery', 'infant school', \n",
    " 'infant care', 'playschool', 'play-group', 'kindergarten', 'childminding', 'babysitting', 'babysitter', \n",
    " 'nanny care', 'children supervision', 'toddler care']\n",
    "\n",
    "df_combined_web_iva_search5= df_combined_web_iva_search3[(df_combined_web_iva_search3['input'].str.contains('|'.join(words_2), case=False, na=False)) \n",
    "                                                            | (df_combined_web_iva_search3['page_name'].str.contains('|'.join(words_2), case=False, na=False))\n",
    "                                                           | (df_combined_web_iva_search3['search_text'].str.contains('|'.join(words_2), case=False, na=False))]\n",
    "# df_combined_web_iva_search4_2 = df_combined_web_iva_search3[df_combined_web_iva_search3['page_name'].str.contains('|'.join(words_2), case=False, na=False)]\n",
    "# df_combined_web_iva_search4_3 = df_combined_web_iva_search3[df_combined_web_iva_search3['search_text'].str.contains('|'.join(words_2), case=False, na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1106709, 29)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_web_iva_search3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481793, 29)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_web_iva_search5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_web_iva_search5 = df_combined_web_iva_search5.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_non_cc_web_iva_search = df_combined_web_iva_search3[(~df_combined_web_iva_search3['input'].str.contains('|'.join(words_2), case=False, na=False))\n",
    "                                                            | (~df_combined_web_iva_search3['page_name'].str.contains('|'.join(words_2), case=False, na=False))\n",
    "                                                           | (~df_combined_web_iva_search3['search_text'].str.contains('|'.join(words_2), case=False, na=False))].head(df_combined_web_iva_search5.shape[0]//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_non_cc_web_iva_search = df_combined_non_cc_web_iva_search.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_cc_model_data = pd.concat([df_combined_web_iva_search5, df_combined_non_cc_web_iva_search], axis=0).sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642390, 29)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_cc_model_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_intnt_entits(text):\n",
    "    doc = nlp(text)\n",
    "    intents = [token.text for token in doc if token.pos_ == 'VERB']\n",
    "    entities = [token.text for token in doc if token.pos_ in {'NOUN', 'PROPN', 'ADJ', 'NUM', 'ADV'}]\n",
    "    return len(intents), len(entities)\n",
    "\n",
    "import re\n",
    "def clean_text(text):\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return clean_text\n",
    "\n",
    "def extract_ner_entities(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "    return entities\n",
    "\n",
    "import numpy as np\n",
    "def length_entities(list_entities):\n",
    "    if (list_entities==np.nan or list_entities==None or list_entities==''):\n",
    "        return 0\n",
    "    else:\n",
    "        return len(list_entities)\n",
    "    \n",
    "# filter_func = lambda x: any(item[1] in [\"PERSON\", \"GPE\", \"ORG\", \"LOC\", \"FAC\"] for item in x)\n",
    "def filter_named_entities(text):\n",
    "    # Process the text using Spacy\n",
    "    doc = nlp(text)\n",
    "    # Filter out named entities (ORG, PERSON, and GPE tags)\n",
    "    filtered_words = [token.text for token in doc if token.ent_type_ not in ['ORG', 'PERSON', 'GPE', \"LOC\", \"FAC\"]]\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "    \n",
    "list_1 = ['ira','RMD','HRdirect','livechat','what is my hsa','P45','Payslip?',\n",
    "    'sps','F80.2','ub','What is YSA','Paystub please','Sh','mfv','C-128','ax','no is hsa','FormL564','HIS','cif','GreT','YSACard',\n",
    "    'Heli','RxPCN','403(b)','Hsa yes or no','ypr','Gv','ONA?','What is UHC?','HC-2','uo','what is 4DX?','osh','what is my hsa?',\n",
    "    'sPRAVATO','sdr','RMD’s','coverage?How','This is for my hsa','pto?','A&DD','childcareplus','fs','mbi','Is that my lowesbenefit.com',\n",
    "    'hra yes','mri?']\n",
    "\n",
    "def text_preprocess(dataframe, list_1):\n",
    "    dataframe = dataframe.drop_duplicates()\n",
    "    dataframe[['no_of_intents', 'no_of_entities']] = dataframe.apply(lambda x: pd.Series(count_intnt_entits(x['input'])), axis=1)  \n",
    "    dataframe['input_cleaned'] = ''\n",
    "    dataframe.loc[dataframe['input'].notnull(), 'input_cleaned'] = dataframe.loc[dataframe['input'].notnull(), 'input'].apply(clean_text)\n",
    "    dataframe.loc[dataframe['page_name'].notnull(), 'page_name_cleaned'] = dataframe.loc[dataframe['page_name'].notnull(), 'page_name'].apply(clean_text)\n",
    "    dataframe.loc[dataframe['search_text'].notnull(), 'search_text_cleaned'] = dataframe.loc[dataframe['search_text'].notnull(), 'search_text'].apply(clean_text)\n",
    "    dataframe['ner_enities'] = ''\n",
    "    dataframe.loc[dataframe['input_cleaned']!='', 'ner_enities'] = dataframe.loc[dataframe['input_cleaned']!='', 'input_cleaned'].apply(extract_ner_entities)\n",
    "    dataframe['len_ner_enities'] = dataframe['ner_enities'].apply(length_entities)\n",
    "    dataframe3 = dataframe[dataframe['len_ner_enities']>0]\n",
    "    dataframe3['input_cleaned'] = dataframe3['input_cleaned'].apply(filter_named_entities)\n",
    "    dataframe6 = pd.concat([dataframe[dataframe['len_ner_enities']==0], dataframe3], axis = 0)\n",
    "    dataframe6 = dataframe6.drop(['no_of_intents','no_of_entities','ner_enities','len_ner_enities'], axis=1)\n",
    "    dataframe6['input_changed']=dataframe6['input']!=dataframe6['input_cleaned']\n",
    "    dataframe6['page_name_changed']=dataframe6['page_name']!=dataframe6['page_name_cleaned']\n",
    "    dataframe6['search_text_changed']=dataframe6['search_text']!=dataframe6['search_text_cleaned']\n",
    "    \n",
    "    # create a new column 'category' containing 'Elder care' for rows where the words in words_2 appear in any of the cleaned text columns\n",
    "    words_1 = ['day care', 'creche', 'child care', \n",
    " 'nursery', 'nursery school', 'preschool', 'after-school care', 'day nursery', 'infant school', \n",
    " 'infant care', 'playschool', 'play-group', 'kindergarten', 'childminding', 'babysitting', 'babysitter', \n",
    " 'nanny care', 'children supervision', 'toddler care']\n",
    "    words_2 = [word.lower() for word in words_1]\n",
    "\n",
    "    def contains_category(text):\n",
    "        for word in words_2:\n",
    "            pattern = r'(?<![^\\W_])' + re.escape(word) + r'(?![^\\W_])'\n",
    "            if re.search(pattern, text.lower()):\n",
    "#                 print(word)\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    dataframe6['category'] = ''\n",
    "    mask = (dataframe6['input_cleaned'].apply(contains_category) |\n",
    "        dataframe6['page_name_cleaned'].apply(contains_category) |\n",
    "        dataframe6['search_text_cleaned'].apply(contains_category)) & (dataframe6['category'] != 'Other')\n",
    "    dataframe6.loc[mask, 'category'] = 'Child care'\n",
    "    dataframe6.loc[dataframe6['category'] == '', 'category'] = 'Other'\n",
    "    \n",
    "    return dataframe6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/1197987153.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[['no_of_intents', 'no_of_entities']] = dataframe.apply(lambda x: pd.Series(count_intnt_entits(x['input'])), axis=1)\n",
      "/tmp/ipykernel_18/1197987153.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[['no_of_intents', 'no_of_entities']] = dataframe.apply(lambda x: pd.Series(count_intnt_entits(x['input'])), axis=1)\n",
      "/tmp/ipykernel_18/1197987153.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['input_cleaned'] = ''\n",
      "/tmp/ipykernel_18/1197987153.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[dataframe['input'].notnull(), 'input_cleaned'] = dataframe.loc[dataframe['input'].notnull(), 'input'].apply(clean_text)\n",
      "/tmp/ipykernel_18/1197987153.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[dataframe['page_name'].notnull(), 'page_name_cleaned'] = dataframe.loc[dataframe['page_name'].notnull(), 'page_name'].apply(clean_text)\n",
      "/tmp/ipykernel_18/1197987153.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[dataframe['search_text'].notnull(), 'search_text_cleaned'] = dataframe.loc[dataframe['search_text'].notnull(), 'search_text'].apply(clean_text)\n",
      "/tmp/ipykernel_18/1197987153.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['ner_enities'] = ''\n",
      "/tmp/ipykernel_18/1197987153.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['len_ner_enities'] = dataframe['ner_enities'].apply(length_entities)\n",
      "/tmp/ipykernel_18/1197987153.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe3['input_cleaned'] = dataframe3['input_cleaned'].apply(filter_named_entities)\n"
     ]
    }
   ],
   "source": [
    "df_combined_cc_model_data_2 = text_preprocess(df_combined_cc_model_data, list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined_cc_model_data_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_cc_model_data_3 = df_combined_cc_model_data_2.drop(['person_id','person_birth_date','person_gender','global_session_id','web_session_id','business_page_name',\n",
    "                                                               'page_type_code','page_type','page_web_type_description','browser_language','page_process_name',\n",
    "                                                                'page_process_detail','person_eeo'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['input', 'session_id', 'person_internal_id', 'client_id', 'yyyymm',\n",
       "       'person_age', 'person_employment_status', 'person_state',\n",
       "       'person_union_vs_non_union', 'person_salary', 'page_name',\n",
       "       'page_domain', 'page_visit_duration', 'session_start_cst',\n",
       "       'search_text', 'search_results', 'input_cleaned', 'page_name_cleaned',\n",
       "       'search_text_cleaned', 'input_changed', 'page_name_changed',\n",
       "       'search_text_changed', 'category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_cc_model_data_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462572, 23)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_cc_model_data_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_cc_model_data_3 = df_combined_cc_model_data_3[[ 'session_id', 'person_internal_id', 'client_id', 'input','input_cleaned',\n",
    "                                                            'search_text','search_text_cleaned', 'page_name','page_name_cleaned',\n",
    "                                                           'category','person_age',\n",
    "        'person_employment_status', 'person_state',\n",
    "       'person_union_vs_non_union', 'person_salary',\n",
    "       'page_domain', 'page_visit_duration',\n",
    "       'session_start_cst',\n",
    "       'search_results', 'yyyymm',\n",
    "        'input_changed', 'page_name_changed',\n",
    "       'search_text_changed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id                           object\n",
       "person_internal_id                    int64\n",
       "client_id                             int64\n",
       "input                                object\n",
       "input_cleaned                        object\n",
       "search_text                          object\n",
       "search_text_cleaned                  object\n",
       "page_name                            object\n",
       "page_name_cleaned                    object\n",
       "category                             object\n",
       "person_age                           object\n",
       "person_employment_status             object\n",
       "person_state                         object\n",
       "person_union_vs_non_union            object\n",
       "person_salary                        object\n",
       "page_domain                          object\n",
       "page_visit_duration                  object\n",
       "session_start_cst            datetime64[ns]\n",
       "search_results                       object\n",
       "yyyymm                               object\n",
       "input_changed                          bool\n",
       "page_name_changed                      bool\n",
       "search_text_changed                    bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_cc_model_data_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_cc_model_data_4 = df_combined_cc_model_data_3.drop(['input','search_text','page_name','input_changed','page_name_changed',\n",
    "                                                               'search_text_changed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_cc_model_data_5 = df_combined_cc_model_data_4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_cc_model_data_5[['person_age','person_salary','page_visit_duration']] = df_combined_cc_model_data_4[['person_age','person_salary','page_visit_duration']].apply(pd.to_numeric,errors='coerce')\n",
    "# combined_ec_model_data_5['person_salary'] = df_combined_ec_model_data_4['person_salary'].to_numeric()\n",
    "# combined_ec_model_data_5['page_visit_duration'] = df_combined_ec_model_data_4['page_visit_duration'].to_numeric()\n",
    "# .astype({\"person_age\": float, \"person_salary\": float, \"page_visit_duration\": float })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462572, 17)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_cc_model_data_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-03-26 22:31:18')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_cc_model_data_5['session_start_cst'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_counts_2 = df_combined_cc_model_data_5.resample('M', on='session_start_cst').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>person_internal_id</th>\n",
       "      <th>client_id</th>\n",
       "      <th>input_cleaned</th>\n",
       "      <th>search_text_cleaned</th>\n",
       "      <th>page_name_cleaned</th>\n",
       "      <th>category</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_employment_status</th>\n",
       "      <th>person_state</th>\n",
       "      <th>person_union_vs_non_union</th>\n",
       "      <th>person_salary</th>\n",
       "      <th>page_domain</th>\n",
       "      <th>page_visit_duration</th>\n",
       "      <th>session_start_cst</th>\n",
       "      <th>search_results</th>\n",
       "      <th>yyyymm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_start_cst</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "      <td>0</td>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "      <td>0</td>\n",
       "      <td>4563</td>\n",
       "      <td>0</td>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30</th>\n",
       "      <td>4426</td>\n",
       "      <td>4426</td>\n",
       "      <td>4426</td>\n",
       "      <td>4426</td>\n",
       "      <td>4426</td>\n",
       "      <td>4426</td>\n",
       "      <td>4426</td>\n",
       "      <td>0</td>\n",
       "      <td>4426</td>\n",
       "      <td>4426</td>\n",
       "      <td>4426</td>\n",
       "      <td>0</td>\n",
       "      <td>4426</td>\n",
       "      <td>0</td>\n",
       "      <td>4426</td>\n",
       "      <td>4426</td>\n",
       "      <td>4426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>764</td>\n",
       "      <td>764</td>\n",
       "      <td>764</td>\n",
       "      <td>764</td>\n",
       "      <td>764</td>\n",
       "      <td>764</td>\n",
       "      <td>764</td>\n",
       "      <td>0</td>\n",
       "      <td>764</td>\n",
       "      <td>764</td>\n",
       "      <td>764</td>\n",
       "      <td>0</td>\n",
       "      <td>764</td>\n",
       "      <td>0</td>\n",
       "      <td>764</td>\n",
       "      <td>764</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31</th>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>18</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>18</td>\n",
       "      <td>921</td>\n",
       "      <td>18</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>15859</td>\n",
       "      <td>15859</td>\n",
       "      <td>15859</td>\n",
       "      <td>15859</td>\n",
       "      <td>15859</td>\n",
       "      <td>15859</td>\n",
       "      <td>15859</td>\n",
       "      <td>13310</td>\n",
       "      <td>15859</td>\n",
       "      <td>15859</td>\n",
       "      <td>15859</td>\n",
       "      <td>11661</td>\n",
       "      <td>15859</td>\n",
       "      <td>15406</td>\n",
       "      <td>15859</td>\n",
       "      <td>15859</td>\n",
       "      <td>15859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>17580</td>\n",
       "      <td>17580</td>\n",
       "      <td>17580</td>\n",
       "      <td>17580</td>\n",
       "      <td>17580</td>\n",
       "      <td>17580</td>\n",
       "      <td>17580</td>\n",
       "      <td>15369</td>\n",
       "      <td>17580</td>\n",
       "      <td>17580</td>\n",
       "      <td>17580</td>\n",
       "      <td>14487</td>\n",
       "      <td>17580</td>\n",
       "      <td>17261</td>\n",
       "      <td>17580</td>\n",
       "      <td>17580</td>\n",
       "      <td>17580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>33909</td>\n",
       "      <td>33909</td>\n",
       "      <td>33909</td>\n",
       "      <td>33909</td>\n",
       "      <td>33909</td>\n",
       "      <td>33909</td>\n",
       "      <td>33909</td>\n",
       "      <td>31765</td>\n",
       "      <td>33909</td>\n",
       "      <td>33909</td>\n",
       "      <td>33909</td>\n",
       "      <td>30683</td>\n",
       "      <td>33909</td>\n",
       "      <td>33382</td>\n",
       "      <td>33909</td>\n",
       "      <td>33909</td>\n",
       "      <td>33909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>20248</td>\n",
       "      <td>20248</td>\n",
       "      <td>20248</td>\n",
       "      <td>20248</td>\n",
       "      <td>20248</td>\n",
       "      <td>20248</td>\n",
       "      <td>20248</td>\n",
       "      <td>19095</td>\n",
       "      <td>20248</td>\n",
       "      <td>20248</td>\n",
       "      <td>20248</td>\n",
       "      <td>18498</td>\n",
       "      <td>20248</td>\n",
       "      <td>19885</td>\n",
       "      <td>20248</td>\n",
       "      <td>20248</td>\n",
       "      <td>20248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>15256</td>\n",
       "      <td>15256</td>\n",
       "      <td>15256</td>\n",
       "      <td>15256</td>\n",
       "      <td>15256</td>\n",
       "      <td>15256</td>\n",
       "      <td>15256</td>\n",
       "      <td>14416</td>\n",
       "      <td>15256</td>\n",
       "      <td>15256</td>\n",
       "      <td>15256</td>\n",
       "      <td>12982</td>\n",
       "      <td>15256</td>\n",
       "      <td>14604</td>\n",
       "      <td>15256</td>\n",
       "      <td>15256</td>\n",
       "      <td>15256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   session_id  person_internal_id  client_id  input_cleaned  \\\n",
       "session_start_cst                                                             \n",
       "2017-09-30                425                 425        425            425   \n",
       "2017-10-31               4563                4563       4563           4563   \n",
       "2017-11-30               4426                4426       4426           4426   \n",
       "2017-12-31                764                 764        764            764   \n",
       "2018-01-31                921                 921        921            921   \n",
       "...                       ...                 ...        ...            ...   \n",
       "2022-11-30              15859               15859      15859          15859   \n",
       "2022-12-31              17580               17580      17580          17580   \n",
       "2023-01-31              33909               33909      33909          33909   \n",
       "2023-02-28              20248               20248      20248          20248   \n",
       "2023-03-31              15256               15256      15256          15256   \n",
       "\n",
       "                   search_text_cleaned  page_name_cleaned  category  \\\n",
       "session_start_cst                                                     \n",
       "2017-09-30                         425                425       425   \n",
       "2017-10-31                        4563               4563      4563   \n",
       "2017-11-30                        4426               4426      4426   \n",
       "2017-12-31                         764                764       764   \n",
       "2018-01-31                         921                921       921   \n",
       "...                                ...                ...       ...   \n",
       "2022-11-30                       15859              15859     15859   \n",
       "2022-12-31                       17580              17580     17580   \n",
       "2023-01-31                       33909              33909     33909   \n",
       "2023-02-28                       20248              20248     20248   \n",
       "2023-03-31                       15256              15256     15256   \n",
       "\n",
       "                   person_age  person_employment_status  person_state  \\\n",
       "session_start_cst                                                       \n",
       "2017-09-30                  0                       425           425   \n",
       "2017-10-31                  0                      4563          4563   \n",
       "2017-11-30                  0                      4426          4426   \n",
       "2017-12-31                  0                       764           764   \n",
       "2018-01-31                 18                       921           921   \n",
       "...                       ...                       ...           ...   \n",
       "2022-11-30              13310                     15859         15859   \n",
       "2022-12-31              15369                     17580         17580   \n",
       "2023-01-31              31765                     33909         33909   \n",
       "2023-02-28              19095                     20248         20248   \n",
       "2023-03-31              14416                     15256         15256   \n",
       "\n",
       "                   person_union_vs_non_union  person_salary  page_domain  \\\n",
       "session_start_cst                                                          \n",
       "2017-09-30                               425              0          425   \n",
       "2017-10-31                              4563              0         4563   \n",
       "2017-11-30                              4426              0         4426   \n",
       "2017-12-31                               764              0          764   \n",
       "2018-01-31                               921             18          921   \n",
       "...                                      ...            ...          ...   \n",
       "2022-11-30                             15859          11661        15859   \n",
       "2022-12-31                             17580          14487        17580   \n",
       "2023-01-31                             33909          30683        33909   \n",
       "2023-02-28                             20248          18498        20248   \n",
       "2023-03-31                             15256          12982        15256   \n",
       "\n",
       "                   page_visit_duration  session_start_cst  search_results  \\\n",
       "session_start_cst                                                           \n",
       "2017-09-30                           0                425             425   \n",
       "2017-10-31                           0               4563            4563   \n",
       "2017-11-30                           0               4426            4426   \n",
       "2017-12-31                           0                764             764   \n",
       "2018-01-31                          18                921             921   \n",
       "...                                ...                ...             ...   \n",
       "2022-11-30                       15406              15859           15859   \n",
       "2022-12-31                       17261              17580           17580   \n",
       "2023-01-31                       33382              33909           33909   \n",
       "2023-02-28                       19885              20248           20248   \n",
       "2023-03-31                       14604              15256           15256   \n",
       "\n",
       "                   yyyymm  \n",
       "session_start_cst          \n",
       "2017-09-30            425  \n",
       "2017-10-31           4563  \n",
       "2017-11-30           4426  \n",
       "2017-12-31            764  \n",
       "2018-01-31            921  \n",
       "...                   ...  \n",
       "2022-11-30          15859  \n",
       "2022-12-31          17580  \n",
       "2023-01-31          33909  \n",
       "2023-02-28          20248  \n",
       "2023-03-31          15256  \n",
       "\n",
       "[67 rows x 17 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_counts_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462572, 17)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_cc_model_data_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-03-26 22:31:18')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_cc_model_data_5['session_start_cst'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filterimg last sox month data as unseen test data\n",
    "start_date = pd.to_datetime('2022-09-26 00:00:00')\n",
    "end_date = df_combined_cc_model_data_5['session_start_cst'].max()\n",
    "unseen_test_df = df_combined_cc_model_data_5[(df_combined_cc_model_data_5['session_start_cst'] >= start_date) & (df_combined_cc_model_data_5['session_start_cst'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131268, 17)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3508498311.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unseen_test_df.fillna(value={'input_cleaned': ' ', 'page_name_cleaned': ' ', 'search_text_cleaned': ' '}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "unseen_test_df.fillna(value={'input_cleaned': ' ', 'page_name_cleaned': ' ', 'search_text_cleaned': ' '}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test_df[['input_cleaned', 'search_text_cleaned', 'page_name_cleaned', 'category']].to_excel('CC_unseen_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_CC_model_df = df_combined_cc_model_data_5[df_combined_cc_model_data_5['session_start_cst'] < start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_CC_model_df.to_excel('final_cc_model_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242317, 17)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_CC_model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_cleaned</th>\n",
       "      <th>search_text_cleaned</th>\n",
       "      <th>page_name_cleaned</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227351</th>\n",
       "      <td>Good morning I was reaching out to find out th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HmCstmChildCarePlusLandingPageOpen</td>\n",
       "      <td>Child care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            input_cleaned search_text_cleaned  \\\n",
       "227351  Good morning I was reaching out to find out th...                 NaN   \n",
       "\n",
       "                         page_name_cleaned    category  \n",
       "227351  HmCstmChildCarePlusLandingPageOpen  Child care  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_excel('final_cc_model_data.xlsx')[['input_cleaned', 'search_text_cleaned', 'page_name_cleaned', 'category']]\n",
    "data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(value={'input_cleaned': ' ', 'page_name_cleaned': ' ', 'search_text_cleaned': ' '}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Child care    195189\n",
       "Other          47128\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_cleaned</th>\n",
       "      <th>search_text_cleaned</th>\n",
       "      <th>page_name_cleaned</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209308</th>\n",
       "      <td>plus</td>\n",
       "      <td>child care plus Coverage</td>\n",
       "      <td>HmCstmChildCarePlusLandingPageOpen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input_cleaned       search_text_cleaned  \\\n",
       "209308          plus  child care plus Coverage   \n",
       "\n",
       "                         page_name_cleaned  category  \n",
       "209308  HmCstmChildCarePlusLandingPageOpen         1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.category = data.category.map({'Other':0, 'Child care':1})\n",
    "data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    195189\n",
       "0     47128\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building on the basis of just text columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5304436680845515\n",
      "Epoch 1 Validation Accuracy: 0.8087652690656982\n",
      "Epoch 1 Confusion Matrix:\n",
      "[[    0  4634]\n",
      " [    0 19598]]\n",
      "Epoch 2 Loss: 0.5277973418736157\n",
      "Epoch 2 Validation Accuracy: 0.8087652690656982\n",
      "Epoch 2 Confusion Matrix:\n",
      "[[    0  4634]\n",
      " [    0 19598]]\n",
      "Epoch 3 Loss: 0.529540378524935\n",
      "Epoch 3 Validation Accuracy: 0.8087652690656982\n",
      "Epoch 3 Confusion Matrix:\n",
      "[[    0  4634]\n",
      " [    0 19598]]\n",
      "Epoch 4 Loss: 0.49855839432886156\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# set the random seed for NumPy\n",
    "np.random.seed(32)\n",
    "\n",
    "# set the random seed for PyTorch\n",
    "torch.manual_seed(32)\n",
    "\n",
    "# load the data\n",
    "# data = pd.read_csv('data.csv')\n",
    "\n",
    "# load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# encode the data using the tokenizer\n",
    "encodings = tokenizer(list(data['input_cleaned']), list(data['search_text_cleaned']), list(data['page_name_cleaned']),\n",
    "                      truncation=True, padding=True)\n",
    "\n",
    "# create the dataset\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(encodings['input_ids']),\n",
    "    torch.tensor(encodings['attention_mask']),\n",
    "    torch.tensor(list(data['category']))\n",
    ")\n",
    "\n",
    "# split the dataset into training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create the DataLoader for the training and validation sets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# load the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2,)\n",
    "\n",
    "# set up the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs=5\n",
    "\n",
    "# train the model\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "    # make predictions on the validation set and compute the accuracy\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "            true_labels.extend(labels.tolist())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f'Epoch {epoch + 1} Validation Accuracy: {accuracy}')\n",
    "\n",
    "    # generate the confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    print(f'Epoch {epoch + 1} Confusion Matrix:')\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to save the model\n",
    "save_path = \"./CC_model_outer_combined_texts_data/\"\n",
    "\n",
    "# create the directory if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# save the model\n",
    "model.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# load the trained model\n",
    "model = BertForSequenceClassification.from_pretrained(save_path)\n",
    "\n",
    "# load the new data to be predicted\n",
    "new_data = pd.read_excel('CC_unseen_data.xlsx')\n",
    "\n",
    "# encode the new data using the tokenizer\n",
    "# encode the new data using the tokenizer\n",
    "input_texts = new_data['input_cleaned'].fillna(' ').tolist()\n",
    "search_texts = new_data['search_text_cleaned'].fillna(' ').tolist()\n",
    "page_names = new_data['page_name_cleaned'].fillna(' ').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = tokenizer(input_texts, search_texts, page_names,\n",
    "                      truncation=True, padding=True)\n",
    "\n",
    "# create the dataset\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(encodings['input_ids']),\n",
    "    torch.tensor(encodings['attention_mask'])\n",
    ")\n",
    "\n",
    "# create the DataLoader for the new data\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# make predictions on the new data\n",
    "predictions = []\n",
    "probabilities = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in loader:\n",
    "        input_ids, attention_mask = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        probabilities.extend(probs[:, 1].tolist())\n",
    "        predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "\n",
    "# new_data['predictions'] = new_data['predictions'].apply(label_predictions)\n",
    "new_data['predictions'] = pd.Series(predictions).apply(lambda x: 'Other' if x==0 else 'Child care' if x==1 else ' ')\n",
    "\n",
    "# new_data['predictions'] = new_data['predictions'].replace({0:'Other', 1:'Elder care'})\n",
    "\n",
    "new_data['probability'] = probabilities\n",
    "# save the new data with predictions\n",
    "new_data.to_csv('CC_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['predictions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the validation set and compute the accuracy\n",
    "predictions = list(new_data['predictions'])\n",
    "true_labels = list(new_data['category'])\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "# generate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "print(cm)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert confusion matrix to pandas dataframe for visualization\n",
    "# labels = ['Other', 'Elder care']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt  \n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# cax = ax.matshow(cm)\n",
    "# plt.title('Confusion matrix of the classifier')\n",
    "# fig.colorbar(cax)\n",
    "# ax.set_xticklabels([''] + labels)\n",
    "# ax.set_yticklabels([''] + labels)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(accuracy)\n",
    "\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Child care','Other']); ax.yaxis.set_ticklabels(['Child care', 'Other']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.12xlarge",
  "kernelspec": {
   "display_name": "python3 (adl-core-custom-docker/1)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:660999144548:image-version/adl-core-custom-docker/1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
